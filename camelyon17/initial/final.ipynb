{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "device = torch.device('cuda:5') if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchinfo\n",
    "writer = SummaryWriter()\n",
    "\n",
    "def create_writer(experiment_name: str, \n",
    "                  model_name: str, \n",
    "                  extra: str=None) -> torch.utils.tensorboard.writer.SummaryWriter():\n",
    "    \"\"\"Creates a torch.utils.tensorboard.writer.SummaryWriter() instance saving to a specific log_dir.\n",
    "\n",
    "    log_dir is a combination of runs/timestamp/experiment_name/model_name/extra.\n",
    "\n",
    "    Where timestamp is the current date in YYYY-MM-DD format.\n",
    "\n",
    "    Args:\n",
    "        experiment_name (str): Name of experiment.\n",
    "        model_name (str): Name of model.\n",
    "        extra (str, optional): Anything extra to add to the directory. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        torch.utils.tensorboard.writer.SummaryWriter(): Instance of a writer saving to log_dir.\n",
    "\n",
    "    Example usage:\n",
    "        # Create a writer saving to \"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\"\n",
    "        writer = create_writer(experiment_name=\"data_10_percent\",\n",
    "                               model_name=\"effnetb2\",\n",
    "                               extra=\"5_epochs\")\n",
    "        # The above is the same as:\n",
    "        writer = SummaryWriter(log_dir=\"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\")\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "\n",
    "    # Get timestamp of current date (all experiments on certain day live in same folder)\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d\") # returns current date in YYYY-MM-DD format\n",
    "\n",
    "    if extra:\n",
    "        # Create log directory path\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name, extra)\n",
    "    else:\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
    "        \n",
    "    print(f\"[INFO] Created SummaryWriter, saving to: {log_dir}...\")\n",
    "    return SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "from tqdm.auto import tqdm\n",
    "def train_step(model: torch.nn.Module,\n",
    "                dataloader: torch.utils.data.DataLoader,\n",
    "                loss_fn: torch.nn.Module,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                device: torch.device) -> Tuple[float,float]:\n",
    "\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0.0,0.0\n",
    "\n",
    "    for batch, (x,y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class==y).sum().item()/len(y_pred)\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device) -> Tuple[float,float]:\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            # print(x.device)\n",
    "            y_pred_logits = model(x)\n",
    "            \n",
    "            loss = loss_fn(y_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            y_pred_labels = torch.argmax(torch.softmax(y_pred_logits, dim=1), dim=1)\n",
    "            test_acc += (y_pred_labels == y).sum().item()/len(y_pred_labels)\n",
    "        \n",
    "    test_loss /= len(dataloader)\n",
    "    test_acc /= len(dataloader)\n",
    "    return test_loss, test_acc\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Add writer parameter to train()\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device, \n",
    "          writer: torch.utils.tensorboard.writer.SummaryWriter # new parameter to take in a writer\n",
    "          ) -> Dict[str, List]:\n",
    "\n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": []\n",
    "    }\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "          dataloader=test_dataloader,\n",
    "          loss_fn=loss_fn,\n",
    "          device=device)\n",
    "\n",
    "        print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "\n",
    "        ### New: Use the writer parameter to track experiments ###\n",
    "        # See if there's a writer, if so, log to it\n",
    "        if writer:\n",
    "            # Add results to SummaryWriter\n",
    "            writer.add_scalars(main_tag=\"Loss\", \n",
    "                               tag_scalar_dict={\"train_loss\": train_loss,\n",
    "                                                \"test_loss\": test_loss},\n",
    "                               global_step=epoch)\n",
    "            writer.add_scalars(main_tag=\"Accuracy\", \n",
    "                               tag_scalar_dict={\"train_acc\": train_acc,\n",
    "                                                \"test_acc\": test_acc}, \n",
    "                               global_step=epoch)\n",
    "\n",
    "            # Close the writer\n",
    "            writer.close()\n",
    "        else:\n",
    "            pass\n",
    "    ### End new ###\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"/local/scratch/camelyon17/camelyon17_v1.0/patches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 50 directories and 0 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches'.\n",
      "There are 0 directories and 2587 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_039_node_1'.\n",
      "There are 0 directories and 10623 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_060_node_3'.\n",
      "There are 0 directories and 1596 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_017_node_1'.\n",
      "There are 0 directories and 5339 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_072_node_0'.\n",
      "There are 0 directories and 5371 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_020_node_4'.\n",
      "There are 0 directories and 1275 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_038_node_2'.\n",
      "There are 0 directories and 5288 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_044_node_4'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 directories and 3950 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_066_node_2'.\n",
      "There are 0 directories and 7727 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_045_node_1'.\n",
      "There are 0 directories and 3808 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_017_node_4'.\n",
      "There are 0 directories and 13455 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_017_node_2'.\n",
      "There are 0 directories and 3466 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_061_node_4'.\n",
      "There are 0 directories and 14703 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_092_node_1'.\n",
      "There are 0 directories and 7294 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_015_node_1'.\n",
      "There are 0 directories and 6956 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_088_node_1'.\n",
      "There are 0 directories and 57375 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_073_node_1'.\n",
      "There are 0 directories and 3427 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_016_node_1'.\n",
      "There are 0 directories and 7395 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_080_node_1'.\n",
      "There are 0 directories and 7958 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_087_node_0'.\n",
      "There are 0 directories and 13637 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_012_node_0'.\n",
      "There are 0 directories and 10661 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_068_node_1'.\n",
      "There are 0 directories and 4046 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_010_node_4'.\n",
      "There are 0 directories and 888 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_024_node_1'.\n",
      "There are 0 directories and 4334 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_046_node_3'.\n",
      "There are 0 directories and 4597 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_009_node_1'.\n",
      "There are 0 directories and 19485 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_075_node_4'.\n",
      "There are 0 directories and 10404 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_022_node_4'.\n",
      "There are 0 directories and 7939 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_086_node_4'.\n",
      "There are 0 directories and 31878 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_051_node_2'.\n",
      "There are 0 directories and 3260 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_015_node_2'.\n",
      "There are 0 directories and 3694 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_041_node_0'.\n",
      "There are 0 directories and 4556 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_048_node_1'.\n",
      "There are 0 directories and 3815 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_046_node_4'.\n",
      "There are 0 directories and 3810 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_040_node_2'.\n",
      "There are 0 directories and 6089 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_067_node_4'.\n",
      "There are 0 directories and 11526 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_081_node_4'.\n",
      "There are 0 directories and 61110 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_096_node_0'.\n",
      "There are 0 directories and 8831 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_062_node_2'.\n",
      "There are 0 directories and 7210 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_042_node_3'.\n",
      "There are 0 directories and 4971 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_034_node_3'.\n",
      "There are 0 directories and 4316 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_004_node_4'.\n",
      "There are 0 directories and 4914 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_089_node_3'.\n",
      "There are 0 directories and 2966 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_024_node_2'.\n",
      "There are 0 directories and 16354 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_099_node_4'.\n",
      "There are 0 directories and 1705 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_021_node_3'.\n",
      "There are 0 directories and 7867 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_086_node_0'.\n",
      "There are 0 directories and 2659 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_036_node_3'.\n",
      "There are 0 directories and 4019 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_064_node_0'.\n",
      "There are 0 directories and 2078 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_020_node_2'.\n",
      "There are 0 directories and 12742 images in '/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_052_node_1'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def walk_through_directory(dir_path):\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
    "\n",
    "walk_through_directory(dir_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random image path: /local/scratch/camelyon17/camelyon17_v1.0/patches/patient_096_node_0/patch_patient_096_node_0_x_36128_y_5664.png\n",
      "Image class: patient_096_node_0\n",
      "Image height: 96\n",
      "Image width: 96\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=96x96>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing random image\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "image_path_list = list(data_path.glob(\"*/*.png\"))\n",
    "random_image_path = random.choice(image_path_list)\n",
    "image_class = random_image_path.parent.stem\n",
    "\n",
    "img = Image.open(random_image_path)\n",
    "\n",
    "print(f\"Random image path: {random_image_path}\")\n",
    "print(f\"Image class: {image_class}\")\n",
    "print(f\"Image height: {img.height}\") \n",
    "print(f\"Image width: {img.width}\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader, Subset, Dataset\n",
    "# from torchvision import datasets, transforms\n",
    "\n",
    "# class DataFromDict(Dataset):\n",
    "#     def __init__(self,input_dict ):\n",
    "#         self.input_dict = input_dict\n",
    "#         self.input_keys = list(input_dict.keys())\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.input_keys)\n",
    "\n",
    "#     def __getitem__(self,idx):\n",
    "#         item = self.input_dict[self.img_keys[idx]]['item_key']\n",
    "#         label = self.input_dict[self.img_keys[idx]]['label_key']\n",
    "#         return item, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader, Subset\n",
    "# from torchvision import datasets, transforms\n",
    "# import numpy as np\n",
    "# import re\n",
    "\n",
    "# image_path_list = list(data_path.glob(\"*/*.png\"))\n",
    "# total_samples=len(image_path_list)\n",
    "# num_samples=20000\n",
    "# indices = torch.tensor(np.random.permutation(np.arange(total_samples))[:num_samples])\n",
    "# # print(total_samples)\n",
    "\n",
    "# regex = re.compile(r'patch_patient_(\\d+)_node_(\\d+)_x_(\\d+)_y_(\\d+).png')\n",
    "\n",
    "# transform=torchvision.transforms.ToTensor()\n",
    "\n",
    "# print(transform(Image.open(image_path_list[0])).shape)\n",
    "\n",
    "# image_dict={}\n",
    "\n",
    "# for i in indices[:10]:\n",
    "#     mo=regex.search(str(image_path_list[i])[69:])\n",
    "#     # print(mo.groups())\n",
    "#     patient,node,x,y = mo.groups()\n",
    "#     patient,node,x,y = int(patient), int(node), int(x), int(y)\n",
    "#     img = transform(np.asarray(Image.open(image_path_list[i]))[:,:,:3])\n",
    "#     image_dict[str(image_path_list[i])] = \n",
    "\n",
    "    \n",
    "\n",
    "# # print(len(\"/local/scratch/camelyon17/camelyon17_v1.0/patches/patient_086_node_0/\"))\n",
    "\n",
    "\n",
    "# complete_data = datasets.ImageFolder(\n",
    "#     root = data_path,\n",
    "#     transform=torchvision.transforms.ToTensor(),\n",
    "# )\n",
    "# complete_data.class_to_idx\n",
    "# # -30,-5\n",
    "# # patch_patient_088_node_1_x_20096_y_14592.png\n",
    "# data = Subset(complete_data, indices)\n",
    "\n",
    "# label_regex = re.compile(r'(\\d\\d\\d)_node_(\\d)')\n",
    "\n",
    "# for i in range(5):\n",
    "#     img, label = data[i][0], data[i][1]\n",
    "#     mo=label_regex.search(complete_data.classes[label])\n",
    "#     patient_number=int(mo.groups()[0])\n",
    "#     node=int(mo.groups()[1])\n",
    "#     print(img.shape, int(mo.groups()[0]), int(mo.groups()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patient</th>\n",
       "      <th>node</th>\n",
       "      <th>x_coord</th>\n",
       "      <th>y_coord</th>\n",
       "      <th>tumor</th>\n",
       "      <th>slide</th>\n",
       "      <th>center</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3328</td>\n",
       "      <td>21792</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3200</td>\n",
       "      <td>22272</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3168</td>\n",
       "      <td>22272</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3328</td>\n",
       "      <td>21760</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3232</td>\n",
       "      <td>22240</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455949</th>\n",
       "      <td>455949</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>14784</td>\n",
       "      <td>7648</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455950</th>\n",
       "      <td>455950</td>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>3872</td>\n",
       "      <td>11328</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455951</th>\n",
       "      <td>455951</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>31968</td>\n",
       "      <td>9536</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455952</th>\n",
       "      <td>455952</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>23712</td>\n",
       "      <td>12192</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455953</th>\n",
       "      <td>455953</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>25408</td>\n",
       "      <td>9120</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455954 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  patient  node  x_coord  y_coord  tumor  slide  center  \\\n",
       "0                0        4     4     3328    21792      1      0       0   \n",
       "1                1        4     4     3200    22272      1      0       0   \n",
       "2                2        4     4     3168    22272      1      0       0   \n",
       "3                3        4     4     3328    21760      1      0       0   \n",
       "4                4        4     4     3232    22240      1      0       0   \n",
       "...            ...      ...   ...      ...      ...    ...    ...     ...   \n",
       "455949      455949       88     1    14784     7648      0     45       4   \n",
       "455950      455950       99     4     3872    11328      0     49       4   \n",
       "455951      455951       92     1    31968     9536      0     47       4   \n",
       "455952      455952       81     4    23712    12192      0     41       4   \n",
       "455953      455953       86     4    25408     9120      0     43       4   \n",
       "\n",
       "        split  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "455949      1  \n",
       "455950      0  \n",
       "455951      0  \n",
       "455952      0  \n",
       "455953      0  \n",
       "\n",
       "[455954 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading metadata.csv\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/local/scratch/camelyon17/camelyon17_v1.0/metadata.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make function to find classes in target directory\n",
    "from typing import Dict, List, Tuple\n",
    "import pathlib\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def custom_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGBA')\n",
    "\n",
    "\n",
    "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "    \"\"\"Finds the class folder names in a target directory.\n",
    "    \n",
    "    Assumes target directory is in standard image classification format.\n",
    "\n",
    "    Args:\n",
    "        directory (str): target directory to load classnames from.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], Dict[str, int]]: (list_of_class_names, dict(class_name: idx...))\n",
    "    \n",
    "    Example:\n",
    "        find_classes(\"food_images/train\")\n",
    "        >>> ([\"class_1\", \"class_2\"], {\"class_1\": 0, ...})\n",
    "    \"\"\"\n",
    "    # 1. Get the class names by scanning the target directory\n",
    "    classes = [\"Non-cancerous\", \"Cancerous\"]\n",
    "    \n",
    "    # 2. Raise an error if class names not found\n",
    "    if not classes:\n",
    "        raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
    "        \n",
    "    # 3. Create a dictionary of index labels (computers prefer numerical rather than string labels)\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "    return classes, class_to_idx\n",
    "\n",
    "# Write a custom dataset class (inherits from torch.utils.data.Dataset)\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 1. Subclass torch.utils.data.Dataset\n",
    "class ImageFolderCustom(Dataset):\n",
    "    \n",
    "    # 2. Initialize with a targ_dir and transform (optional) parameter\n",
    "    def __init__(self, targ_dir: str, transform=None) -> None:\n",
    "        \n",
    "        # 3. Create class attributes\n",
    "        # Get all image paths\n",
    "        self.paths = list(pathlib.Path(targ_dir).glob(\"*/*.png\")) # note: you'd have to update this if you've got .png's or .jpeg's\n",
    "        # Setup transforms\n",
    "        self.transform = transform\n",
    "        # Create classes and class_to_idx attributes\n",
    "        self.classes, self.class_to_idx = find_classes(targ_dir)\n",
    "\n",
    "    # 4. Make function to load images\n",
    "    def load_image(self, index: int) -> Image.Image:\n",
    "        \"Opens an image via a path and returns it.\"\n",
    "        image_path = self.paths[index]\n",
    "        return Image.open(image_path) \n",
    "    \n",
    "    # 5. Overwrite the __len__() method (optional but recommended for subclasses of torch.utils.data.Dataset)\n",
    "    def __len__(self) -> int:\n",
    "        \"Returns the total number of samples.\"\n",
    "        return len(self.paths)\n",
    "    \n",
    "    # 6. Overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"Returns one sample of data, data and label (X, y).\"\n",
    "        img = self.load_image(index)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img_arr = np.asarray(img)[32:64, 32:64, :]\n",
    "        img = Image.fromarray(img_arr)\n",
    "        image_path = self.paths[index]\n",
    "        regex = re.compile(r'patch_patient_(\\d+)_node_(\\d+)_x_(\\d+)_y_(\\d+).png')\n",
    "        mo=regex.search(str(image_path)[69:])\n",
    "    # print(mo.groups())\n",
    "        patient,node,x,y = mo.groups()\n",
    "        patient,node,x,y = int(patient), int(node), int(x), int(y)\n",
    "\n",
    "        has_cancer = int(df[(df[\"patient\"] == patient) & (df[\"node\"] == node) & (df[\"x_coord\"] == x) & (df[\"y_coord\"] == y)][\"tumor\"].iloc[0])     \n",
    "        class_name  = \"Cancerous\" if has_cancer else \"Non-cancerous\" # expects path in data_folder/class_name/image.jpeg\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "        # Transform if necessary\n",
    "        if self.transform:\n",
    "            return self.transform(img), class_idx # return data, label (X, y)\n",
    "        else:\n",
    "            return img, class_idx # return data, label (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455954\n",
      "torch.Size([3, 32, 32]) 0\n",
      "['Non-cancerous', 'Cancerous']\n",
      "{'Non-cancerous': 0, 'Cancerous': 1}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data = ImageFolderCustom(\n",
    "    targ_dir = data_path,\n",
    "    transform=data_transform\n",
    ")\n",
    "print(len(data))\n",
    "print(data[0][0].shape, data[0][1])\n",
    "print(data.classes)\n",
    "print(data.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = int(df[(df[\"patient\"] == 39) & (df[\"node\"] == 1) & (df[\"x_coord\"] == 7872) & (df[\"y_coord\"] == 30432)][\"tumor\"].iloc[0])\n",
    "# print(l)\n",
    "# img = Image.open(image_path_list[0])\n",
    "# img_arr = np.asarray(img)[:,32:64, 32:64]\n",
    "# print(img_arr.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TinyVGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455954\n",
      "torch.Size([3, 32, 32]) 0\n",
      "['Non-cancerous', 'Cancerous']\n",
      "{'Non-cancerous': 0, 'Cancerous': 1}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "data = ImageFolderCustom(\n",
    "    targ_dir = data_path,\n",
    "    transform=manual_transform\n",
    ")\n",
    "print(len(data))\n",
    "print(data[0][0].shape, data[0][1])\n",
    "print(data.classes)\n",
    "print(data.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 20000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy\n",
    "\n",
    "\n",
    "manual_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "total_samples=len(data)\n",
    "num_samples=100000\n",
    "\n",
    "\n",
    "indices=torch.tensor(numpy.random.permutation(numpy.arange(total_samples))[:num_samples])\n",
    "\n",
    "train_indices=indices[:int(0.8*num_samples)]\n",
    "test_indices=indices[int(0.8*num_samples):]\n",
    "\n",
    "train_dataset=Subset(data, train_indices)\n",
    "test_dataset=Subset(data, test_indices)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    def __init__(self, input_channels: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels = input_channels,\n",
    "                out_channels = hidden_units,\n",
    "                kernel_size = 3,\n",
    "                stride = 1,\n",
    "                padding = 1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels= hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride = 1,\n",
    "                padding = 1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(\n",
    "                in_features = hidden_units* (IMAGE_SIZE//4) * (IMAGE_SIZE//4),\n",
    "                out_features = output_shape\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.conv_block_2(self.conv_block_1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = TinyVGG(input_channels=3, hidden_units=10, output_shape=2).to(device)\n",
    "# torchinfo.summary(model0, (1,3,224,224))\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model0.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "Logits:  tensor([[0.0467, 0.0489]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "Prob:  tensor([[0.4995, 0.5005]], device='cuda:2', grad_fn=<SoftmaxBackward0>)\n",
      "Predicted label:  tensor([1], device='cuda:2')\n",
      "Real Label:  tensor(1)\n"
     ]
    }
   ],
   "source": [
    "#example forward pass\n",
    "img, label = next(iter(test_dataloader))\n",
    "img = img[0].unsqueeze(dim=0).to(device)\n",
    "label = label[0]\n",
    "# \n",
    "print(img[0].shape)\n",
    "y_pred_logits = model0(img)\n",
    "print(\"Logits: \", y_pred_logits)\n",
    "y_pred_prob = torch.softmax(y_pred_logits, dim=1)\n",
    "print(\"Prob: \", y_pred_prob)\n",
    "y_pred_label = torch.argmax(y_pred_prob, dim=1)\n",
    "print(\"Predicted label: \", y_pred_label)\n",
    "print(\"Real Label: \", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 1/10 [01:55<17:22, 115.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.6195 | train_acc: 0.6416 | test_loss: 0.5135 | test_acc: 0.7433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 2/10 [03:35<14:11, 106.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.5034 | train_acc: 0.7603 | test_loss: 0.4530 | test_acc: 0.7952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 3/10 [05:18<12:13, 104.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.4383 | train_acc: 0.8036 | test_loss: 0.3614 | test_acc: 0.8478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 4/10 [07:01<10:25, 104.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.3890 | train_acc: 0.8355 | test_loss: 0.3882 | test_acc: 0.8256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 5/10 [08:45<08:39, 103.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.3623 | train_acc: 0.8498 | test_loss: 0.3370 | test_acc: 0.8640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 6/10 [10:27<06:53, 103.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | train_loss: 0.3447 | train_acc: 0.8590 | test_loss: 0.3110 | test_acc: 0.8731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 7/10 [12:11<05:10, 103.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | train_loss: 0.3309 | train_acc: 0.8659 | test_loss: 0.3304 | test_acc: 0.8713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 8/10 [13:54<03:26, 103.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | train_loss: 0.3225 | train_acc: 0.8698 | test_loss: 0.2883 | test_acc: 0.8859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 9/10 [15:39<01:43, 103.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | train_loss: 0.3139 | train_acc: 0.8735 | test_loss: 0.3098 | test_acc: 0.8744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [17:23<00:00, 104.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | train_loss: 0.3076 | train_acc: 0.8772 | test_loss: 0.2893 | test_acc: 0.8845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [0.6194567772388458,\n",
       "  0.5034450042784214,\n",
       "  0.4383050509572029,\n",
       "  0.38896895580291746,\n",
       "  0.3622746847748756,\n",
       "  0.3446577535867691,\n",
       "  0.33089231877326963,\n",
       "  0.3224909020721912,\n",
       "  0.31389375881552695,\n",
       "  0.30764368366003036],\n",
       " 'train_acc': [0.641625,\n",
       "  0.76035,\n",
       "  0.803575,\n",
       "  0.8355,\n",
       "  0.8498,\n",
       "  0.8589625,\n",
       "  0.865875,\n",
       "  0.86975,\n",
       "  0.8735375,\n",
       "  0.8772],\n",
       " 'test_loss': [0.5135014057636261,\n",
       "  0.45302165760993957,\n",
       "  0.3613624082326889,\n",
       "  0.3881845613718033,\n",
       "  0.33700660697221757,\n",
       "  0.31100391194820404,\n",
       "  0.3304460021853447,\n",
       "  0.28832855656147005,\n",
       "  0.309759696829319,\n",
       "  0.2893071149945259],\n",
       " 'test_acc': [0.7433,\n",
       "  0.79515,\n",
       "  0.84775,\n",
       "  0.82565,\n",
       "  0.86405,\n",
       "  0.8731,\n",
       "  0.8713,\n",
       "  0.8859,\n",
       "  0.8744,\n",
       "  0.88455]}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model0, train_dataloader, test_dataloader, optimizer, loss_fn, 10, device, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = Path(\"models/TinyVGG_100k.pt\")\n",
    "torch.save(obj=model0.state_dict(), f=SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient Net b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type (var_name))                                      Output Shape         Param #\n",
       "====================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [64, 1000]           --\n",
       "Sequential (features)                                      [64, 1280, 7, 7]     --\n",
       "    Conv2dNormActivation (0)                              [64, 32, 112, 112]   --\n",
       "        Conv2d (0)                                       [64, 32, 112, 112]   864\n",
       "        BatchNorm2d (1)                                  [64, 32, 112, 112]   64\n",
       "        SiLU (2)                                         [64, 32, 112, 112]   --\n",
       "    Sequential (1)                                        [64, 16, 112, 112]   --\n",
       "        MBConv (0)                                       [64, 16, 112, 112]   1,448\n",
       "    Sequential (2)                                        [64, 24, 56, 56]     --\n",
       "        MBConv (0)                                       [64, 24, 56, 56]     6,004\n",
       "        MBConv (1)                                       [64, 24, 56, 56]     10,710\n",
       "    Sequential (3)                                        [64, 40, 28, 28]     --\n",
       "        MBConv (0)                                       [64, 40, 28, 28]     15,350\n",
       "        MBConv (1)                                       [64, 40, 28, 28]     31,290\n",
       "    Sequential (4)                                        [64, 80, 14, 14]     --\n",
       "        MBConv (0)                                       [64, 80, 14, 14]     37,130\n",
       "        MBConv (1)                                       [64, 80, 14, 14]     102,900\n",
       "        MBConv (2)                                       [64, 80, 14, 14]     102,900\n",
       "    Sequential (5)                                        [64, 112, 14, 14]    --\n",
       "        MBConv (0)                                       [64, 112, 14, 14]    126,004\n",
       "        MBConv (1)                                       [64, 112, 14, 14]    208,572\n",
       "        MBConv (2)                                       [64, 112, 14, 14]    208,572\n",
       "    Sequential (6)                                        [64, 192, 7, 7]      --\n",
       "        MBConv (0)                                       [64, 192, 7, 7]      262,492\n",
       "        MBConv (1)                                       [64, 192, 7, 7]      587,952\n",
       "        MBConv (2)                                       [64, 192, 7, 7]      587,952\n",
       "        MBConv (3)                                       [64, 192, 7, 7]      587,952\n",
       "    Sequential (7)                                        [64, 320, 7, 7]      --\n",
       "        MBConv (0)                                       [64, 320, 7, 7]      717,232\n",
       "    Conv2dNormActivation (8)                              [64, 1280, 7, 7]     --\n",
       "        Conv2d (0)                                       [64, 1280, 7, 7]     409,600\n",
       "        BatchNorm2d (1)                                  [64, 1280, 7, 7]     2,560\n",
       "        SiLU (2)                                         [64, 1280, 7, 7]     --\n",
       "AdaptiveAvgPool2d (avgpool)                                [64, 1280, 1, 1]     --\n",
       "Sequential (classifier)                                    [64, 1000]           --\n",
       "    Dropout (0)                                           [64, 1280]           --\n",
       "    Linear (1)                                            [64, 1000]           1,281,000\n",
       "====================================================================================================\n",
       "Total params: 5,288,548\n",
       "Trainable params: 5,288,548\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 24.70\n",
       "====================================================================================================\n",
       "Input size (MB): 38.54\n",
       "Forward/backward pass size (MB): 6904.69\n",
       "Params size (MB): 21.15\n",
       "Estimated Total Size (MB): 6964.38\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
    "torchinfo.summary(\n",
    "    model=model,\n",
    "    input_size=(64,3,224,224),\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 20000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy\n",
    "\n",
    "\n",
    "auto_transform = weights.transforms()\n",
    "data = ImageFolderCustom(\n",
    "    targ_dir = data_path,\n",
    "    transform=auto_transform\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "total_samples=len(data)\n",
    "num_samples=100000\n",
    "\n",
    "\n",
    "indices=torch.tensor(numpy.random.permutation(numpy.arange(total_samples))[:num_samples])\n",
    "\n",
    "train_indices=indices[:int(0.8*num_samples)]\n",
    "test_indices=indices[int(0.8*num_samples):]\n",
    "\n",
    "train_dataset=Subset(data, train_indices)\n",
    "test_dataset=Subset(data, test_indices)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type (var_name))                                      Output Shape         Param #\n",
       "====================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [64, 2]              --\n",
       "Sequential (features)                                      [64, 1280, 7, 7]     --\n",
       "    Conv2dNormActivation (0)                              [64, 32, 112, 112]   --\n",
       "        Conv2d (0)                                       [64, 32, 112, 112]   (864)\n",
       "        BatchNorm2d (1)                                  [64, 32, 112, 112]   (64)\n",
       "        SiLU (2)                                         [64, 32, 112, 112]   --\n",
       "    Sequential (1)                                        [64, 16, 112, 112]   --\n",
       "        MBConv (0)                                       [64, 16, 112, 112]   (1,448)\n",
       "    Sequential (2)                                        [64, 24, 56, 56]     --\n",
       "        MBConv (0)                                       [64, 24, 56, 56]     (6,004)\n",
       "        MBConv (1)                                       [64, 24, 56, 56]     (10,710)\n",
       "    Sequential (3)                                        [64, 40, 28, 28]     --\n",
       "        MBConv (0)                                       [64, 40, 28, 28]     (15,350)\n",
       "        MBConv (1)                                       [64, 40, 28, 28]     (31,290)\n",
       "    Sequential (4)                                        [64, 80, 14, 14]     --\n",
       "        MBConv (0)                                       [64, 80, 14, 14]     (37,130)\n",
       "        MBConv (1)                                       [64, 80, 14, 14]     (102,900)\n",
       "        MBConv (2)                                       [64, 80, 14, 14]     (102,900)\n",
       "    Sequential (5)                                        [64, 112, 14, 14]    --\n",
       "        MBConv (0)                                       [64, 112, 14, 14]    (126,004)\n",
       "        MBConv (1)                                       [64, 112, 14, 14]    (208,572)\n",
       "        MBConv (2)                                       [64, 112, 14, 14]    (208,572)\n",
       "    Sequential (6)                                        [64, 192, 7, 7]      --\n",
       "        MBConv (0)                                       [64, 192, 7, 7]      (262,492)\n",
       "        MBConv (1)                                       [64, 192, 7, 7]      (587,952)\n",
       "        MBConv (2)                                       [64, 192, 7, 7]      (587,952)\n",
       "        MBConv (3)                                       [64, 192, 7, 7]      (587,952)\n",
       "    Sequential (7)                                        [64, 320, 7, 7]      --\n",
       "        MBConv (0)                                       [64, 320, 7, 7]      (717,232)\n",
       "    Conv2dNormActivation (8)                              [64, 1280, 7, 7]     --\n",
       "        Conv2d (0)                                       [64, 1280, 7, 7]     (409,600)\n",
       "        BatchNorm2d (1)                                  [64, 1280, 7, 7]     (2,560)\n",
       "        SiLU (2)                                         [64, 1280, 7, 7]     --\n",
       "AdaptiveAvgPool2d (avgpool)                                [64, 1280, 1, 1]     --\n",
       "Sequential (classifier)                                    [64, 2]              --\n",
       "    Dropout (0)                                           [64, 1280]           --\n",
       "    Linear (1)                                            [64, 2]              2,562\n",
       "====================================================================================================\n",
       "Total params: 4,010,110\n",
       "Trainable params: 2,562\n",
       "Non-trainable params: 4,007,548\n",
       "Total mult-adds (G): 24.61\n",
       "====================================================================================================\n",
       "Input size (MB): 38.54\n",
       "Forward/backward pass size (MB): 6904.18\n",
       "Params size (MB): 16.04\n",
       "Estimated Total Size (MB): 6958.76\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.features.parameters():\n",
    "    param.requires_grad=False\n",
    "\n",
    "output_shape = len(data.classes)\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=output_shape)\n",
    ").to(device)\n",
    "\n",
    "torchinfo.summary(\n",
    "    model=model,\n",
    "    input_size=(64,3,224,224),\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 1/10 [03:33<32:03, 213.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.4188 | train_acc: 0.8175 | test_loss: 0.3557 | test_acc: 0.8505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 2/10 [06:31<25:39, 192.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.4036 | train_acc: 0.8258 | test_loss: 0.3472 | test_acc: 0.8603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 3/10 [09:30<21:43, 186.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.4031 | train_acc: 0.8253 | test_loss: 0.3518 | test_acc: 0.8537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 4/10 [12:27<18:16, 182.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.4050 | train_acc: 0.8255 | test_loss: 0.3551 | test_acc: 0.8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 5/10 [15:26<15:07, 181.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.4009 | train_acc: 0.8274 | test_loss: 0.3487 | test_acc: 0.8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 6/10 [18:24<12:00, 180.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | train_loss: 0.4054 | train_acc: 0.8243 | test_loss: 0.3456 | test_acc: 0.8559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 7/10 [21:23<08:59, 179.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | train_loss: 0.4055 | train_acc: 0.8226 | test_loss: 0.3456 | test_acc: 0.8597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 8/10 [24:30<06:04, 182.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | train_loss: 0.4036 | train_acc: 0.8248 | test_loss: 0.3556 | test_acc: 0.8471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 9/10 [27:29<03:01, 181.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | train_loss: 0.4047 | train_acc: 0.8245 | test_loss: 0.3445 | test_acc: 0.8574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [30:26<00:00, 182.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | train_loss: 0.4052 | train_acc: 0.8239 | test_loss: 0.3462 | test_acc: 0.8575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=10,\n",
    "    device=device,\n",
    "    writer=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = Path(\"models/EfficientNet_b0_100k.pt\")\n",
    "torch.save(obj=model.state_dict(), f=SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNeXt-50-32x4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type (var_name):depth-idx)                  Output Shape         Param #\n",
       "==========================================================================================\n",
       "ResNet (ResNet)                                    [64, 1000]           --\n",
       "+ Conv2d (conv1): 1-1                              [64, 64, 112, 112]   9,408\n",
       "+ BatchNorm2d (bn1): 1-2                           [64, 64, 112, 112]   128\n",
       "+ ReLU (relu): 1-3                                 [64, 64, 112, 112]   --\n",
       "+ MaxPool2d (maxpool): 1-4                         [64, 64, 56, 56]     --\n",
       "+ Sequential (layer1): 1-5                         [64, 256, 56, 56]    --\n",
       "|    + Bottleneck (0): 2-1                         [64, 256, 56, 56]    --\n",
       "|    |    + Conv2d (conv1): 3-1                    [64, 128, 56, 56]    8,192\n",
       "|    |    + BatchNorm2d (bn1): 3-2                 [64, 128, 56, 56]    256\n",
       "|    |    + ReLU (relu): 3-3                       [64, 128, 56, 56]    --\n",
       "|    |    + Conv2d (conv2): 3-4                    [64, 128, 56, 56]    4,608\n",
       "|    |    + BatchNorm2d (bn2): 3-5                 [64, 128, 56, 56]    256\n",
       "|    |    + ReLU (relu): 3-6                       [64, 128, 56, 56]    --\n",
       "|    |    + Conv2d (conv3): 3-7                    [64, 256, 56, 56]    32,768\n",
       "|    |    + BatchNorm2d (bn3): 3-8                 [64, 256, 56, 56]    512\n",
       "|    |    + Sequential (downsample): 3-9           [64, 256, 56, 56]    16,896\n",
       "|    |    + ReLU (relu): 3-10                      [64, 256, 56, 56]    --\n",
       "|    + Bottleneck (1): 2-2                         [64, 256, 56, 56]    --\n",
       "|    |    + Conv2d (conv1): 3-11                   [64, 128, 56, 56]    32,768\n",
       "|    |    + BatchNorm2d (bn1): 3-12                [64, 128, 56, 56]    256\n",
       "|    |    + ReLU (relu): 3-13                      [64, 128, 56, 56]    --\n",
       "|    |    + Conv2d (conv2): 3-14                   [64, 128, 56, 56]    4,608\n",
       "|    |    + BatchNorm2d (bn2): 3-15                [64, 128, 56, 56]    256\n",
       "|    |    + ReLU (relu): 3-16                      [64, 128, 56, 56]    --\n",
       "|    |    + Conv2d (conv3): 3-17                   [64, 256, 56, 56]    32,768\n",
       "|    |    + BatchNorm2d (bn3): 3-18                [64, 256, 56, 56]    512\n",
       "|    |    + ReLU (relu): 3-19                      [64, 256, 56, 56]    --\n",
       "|    + Bottleneck (2): 2-3                         [64, 256, 56, 56]    --\n",
       "|    |    + Conv2d (conv1): 3-20                   [64, 128, 56, 56]    32,768\n",
       "|    |    + BatchNorm2d (bn1): 3-21                [64, 128, 56, 56]    256\n",
       "|    |    + ReLU (relu): 3-22                      [64, 128, 56, 56]    --\n",
       "|    |    + Conv2d (conv2): 3-23                   [64, 128, 56, 56]    4,608\n",
       "|    |    + BatchNorm2d (bn2): 3-24                [64, 128, 56, 56]    256\n",
       "|    |    + ReLU (relu): 3-25                      [64, 128, 56, 56]    --\n",
       "|    |    + Conv2d (conv3): 3-26                   [64, 256, 56, 56]    32,768\n",
       "|    |    + BatchNorm2d (bn3): 3-27                [64, 256, 56, 56]    512\n",
       "|    |    + ReLU (relu): 3-28                      [64, 256, 56, 56]    --\n",
       "+ Sequential (layer2): 1-6                         [64, 512, 28, 28]    --\n",
       "|    + Bottleneck (0): 2-4                         [64, 512, 28, 28]    --\n",
       "|    |    + Conv2d (conv1): 3-29                   [64, 256, 56, 56]    65,536\n",
       "|    |    + BatchNorm2d (bn1): 3-30                [64, 256, 56, 56]    512\n",
       "|    |    + ReLU (relu): 3-31                      [64, 256, 56, 56]    --\n",
       "|    |    + Conv2d (conv2): 3-32                   [64, 256, 28, 28]    18,432\n",
       "|    |    + BatchNorm2d (bn2): 3-33                [64, 256, 28, 28]    512\n",
       "|    |    + ReLU (relu): 3-34                      [64, 256, 28, 28]    --\n",
       "|    |    + Conv2d (conv3): 3-35                   [64, 512, 28, 28]    131,072\n",
       "|    |    + BatchNorm2d (bn3): 3-36                [64, 512, 28, 28]    1,024\n",
       "|    |    + Sequential (downsample): 3-37          [64, 512, 28, 28]    132,096\n",
       "|    |    + ReLU (relu): 3-38                      [64, 512, 28, 28]    --\n",
       "|    + Bottleneck (1): 2-5                         [64, 512, 28, 28]    --\n",
       "|    |    + Conv2d (conv1): 3-39                   [64, 256, 28, 28]    131,072\n",
       "|    |    + BatchNorm2d (bn1): 3-40                [64, 256, 28, 28]    512\n",
       "|    |    + ReLU (relu): 3-41                      [64, 256, 28, 28]    --\n",
       "|    |    + Conv2d (conv2): 3-42                   [64, 256, 28, 28]    18,432\n",
       "|    |    + BatchNorm2d (bn2): 3-43                [64, 256, 28, 28]    512\n",
       "|    |    + ReLU (relu): 3-44                      [64, 256, 28, 28]    --\n",
       "|    |    + Conv2d (conv3): 3-45                   [64, 512, 28, 28]    131,072\n",
       "|    |    + BatchNorm2d (bn3): 3-46                [64, 512, 28, 28]    1,024\n",
       "|    |    + ReLU (relu): 3-47                      [64, 512, 28, 28]    --\n",
       "|    + Bottleneck (2): 2-6                         [64, 512, 28, 28]    --\n",
       "|    |    + Conv2d (conv1): 3-48                   [64, 256, 28, 28]    131,072\n",
       "|    |    + BatchNorm2d (bn1): 3-49                [64, 256, 28, 28]    512\n",
       "|    |    + ReLU (relu): 3-50                      [64, 256, 28, 28]    --\n",
       "|    |    + Conv2d (conv2): 3-51                   [64, 256, 28, 28]    18,432\n",
       "|    |    + BatchNorm2d (bn2): 3-52                [64, 256, 28, 28]    512\n",
       "|    |    + ReLU (relu): 3-53                      [64, 256, 28, 28]    --\n",
       "|    |    + Conv2d (conv3): 3-54                   [64, 512, 28, 28]    131,072\n",
       "|    |    + BatchNorm2d (bn3): 3-55                [64, 512, 28, 28]    1,024\n",
       "|    |    + ReLU (relu): 3-56                      [64, 512, 28, 28]    --\n",
       "|    + Bottleneck (3): 2-7                         [64, 512, 28, 28]    --\n",
       "|    |    + Conv2d (conv1): 3-57                   [64, 256, 28, 28]    131,072\n",
       "|    |    + BatchNorm2d (bn1): 3-58                [64, 256, 28, 28]    512\n",
       "|    |    + ReLU (relu): 3-59                      [64, 256, 28, 28]    --\n",
       "|    |    + Conv2d (conv2): 3-60                   [64, 256, 28, 28]    18,432\n",
       "|    |    + BatchNorm2d (bn2): 3-61                [64, 256, 28, 28]    512\n",
       "|    |    + ReLU (relu): 3-62                      [64, 256, 28, 28]    --\n",
       "|    |    + Conv2d (conv3): 3-63                   [64, 512, 28, 28]    131,072\n",
       "|    |    + BatchNorm2d (bn3): 3-64                [64, 512, 28, 28]    1,024\n",
       "|    |    + ReLU (relu): 3-65                      [64, 512, 28, 28]    --\n",
       "+ Sequential (layer3): 1-7                         [64, 1024, 14, 14]   --\n",
       "|    + Bottleneck (0): 2-8                         [64, 1024, 14, 14]   --\n",
       "|    |    + Conv2d (conv1): 3-66                   [64, 512, 28, 28]    262,144\n",
       "|    |    + BatchNorm2d (bn1): 3-67                [64, 512, 28, 28]    1,024\n",
       "|    |    + ReLU (relu): 3-68                      [64, 512, 28, 28]    --\n",
       "|    |    + Conv2d (conv2): 3-69                   [64, 512, 14, 14]    73,728\n",
       "|    |    + BatchNorm2d (bn2): 3-70                [64, 512, 14, 14]    1,024\n",
       "|    |    + ReLU (relu): 3-71                      [64, 512, 14, 14]    --\n",
       "|    |    + Conv2d (conv3): 3-72                   [64, 1024, 14, 14]   524,288\n",
       "|    |    + BatchNorm2d (bn3): 3-73                [64, 1024, 14, 14]   2,048\n",
       "|    |    + Sequential (downsample): 3-74          [64, 1024, 14, 14]   526,336\n",
       "|    |    + ReLU (relu): 3-75                      [64, 1024, 14, 14]   --\n",
       "|    + Bottleneck (1): 2-9                         [64, 1024, 14, 14]   --\n",
       "|    |    + Conv2d (conv1): 3-76                   [64, 512, 14, 14]    524,288\n",
       "|    |    + BatchNorm2d (bn1): 3-77                [64, 512, 14, 14]    1,024\n",
       "|    |    + ReLU (relu): 3-78                      [64, 512, 14, 14]    --\n",
       "|    |    + Conv2d (conv2): 3-79                   [64, 512, 14, 14]    73,728\n",
       "|    |    + BatchNorm2d (bn2): 3-80                [64, 512, 14, 14]    1,024\n",
       "|    |    + ReLU (relu): 3-81                      [64, 512, 14, 14]    --\n",
       "|    |    + Conv2d (conv3): 3-82                   [64, 1024, 14, 14]   524,288\n",
       "|    |    + BatchNorm2d (bn3): 3-83                [64, 1024, 14, 14]   2,048\n",
       "|    |    + ReLU (relu): 3-84                      [64, 1024, 14, 14]   --\n",
       "|    + Bottleneck (2): 2-10                        [64, 1024, 14, 14]   --\n",
       "|    |    + Conv2d (conv1): 3-85                   [64, 512, 14, 14]    524,288\n",
       "|    |    + BatchNorm2d (bn1): 3-86                [64, 512, 14, 14]    1,024\n",
       "|    |    + ReLU (relu): 3-87                      [64, 512, 14, 14]    --\n",
       "|    |    + Conv2d (conv2): 3-88                   [64, 512, 14, 14]    73,728\n",
       "|    |    + BatchNorm2d (bn2): 3-89                [64, 512, 14, 14]    1,024\n",
       "|    |    + ReLU (relu): 3-90                      [64, 512, 14, 14]    --\n",
       "|    |    + Conv2d (conv3): 3-91                   [64, 1024, 14, 14]   524,288\n",
       "|    |    + BatchNorm2d (bn3): 3-92                [64, 1024, 14, 14]   2,048\n",
       "|    |    + ReLU (relu): 3-93                      [64, 1024, 14, 14]   --\n",
       "|    + Bottleneck (3): 2-11                        [64, 1024, 14, 14]   --\n",
       "|    |    + Conv2d (conv1): 3-94                   [64, 512, 14, 14]    524,288\n",
       "|    |    + BatchNorm2d (bn1): 3-95                [64, 512, 14, 14]    1,024\n",
       "|    |    + ReLU (relu): 3-96                      [64, 512, 14, 14]    --\n",
       "|    |    + Conv2d (conv2): 3-97                   [64, 512, 14, 14]    73,728\n",
       "|    |    + BatchNorm2d (bn2): 3-98                [64, 512, 14, 14]    1,024\n",
       "|    |    + ReLU (relu): 3-99                      [64, 512, 14, 14]    --\n",
       "|    |    + Conv2d (conv3): 3-100                  [64, 1024, 14, 14]   524,288\n",
       "|    |    + BatchNorm2d (bn3): 3-101               [64, 1024, 14, 14]   2,048\n",
       "|    |    + ReLU (relu): 3-102                     [64, 1024, 14, 14]   --\n",
       "|    + Bottleneck (4): 2-12                        [64, 1024, 14, 14]   --\n",
       "|    |    + Conv2d (conv1): 3-103                  [64, 512, 14, 14]    524,288\n",
       "|    |    + BatchNorm2d (bn1): 3-104               [64, 512, 14, 14]    1,024\n",
       "|    |    + ReLU (relu): 3-105                     [64, 512, 14, 14]    --\n",
       "|    |    + Conv2d (conv2): 3-106                  [64, 512, 14, 14]    73,728\n",
       "|    |    + BatchNorm2d (bn2): 3-107               [64, 512, 14, 14]    1,024\n",
       "|    |    + ReLU (relu): 3-108                     [64, 512, 14, 14]    --\n",
       "|    |    + Conv2d (conv3): 3-109                  [64, 1024, 14, 14]   524,288\n",
       "|    |    + BatchNorm2d (bn3): 3-110               [64, 1024, 14, 14]   2,048\n",
       "|    |    + ReLU (relu): 3-111                     [64, 1024, 14, 14]   --\n",
       "|    + Bottleneck (5): 2-13                        [64, 1024, 14, 14]   --\n",
       "|    |    + Conv2d (conv1): 3-112                  [64, 512, 14, 14]    524,288\n",
       "|    |    + BatchNorm2d (bn1): 3-113               [64, 512, 14, 14]    1,024\n",
       "|    |    + ReLU (relu): 3-114                     [64, 512, 14, 14]    --\n",
       "|    |    + Conv2d (conv2): 3-115                  [64, 512, 14, 14]    73,728\n",
       "|    |    + BatchNorm2d (bn2): 3-116               [64, 512, 14, 14]    1,024\n",
       "|    |    + ReLU (relu): 3-117                     [64, 512, 14, 14]    --\n",
       "|    |    + Conv2d (conv3): 3-118                  [64, 1024, 14, 14]   524,288\n",
       "|    |    + BatchNorm2d (bn3): 3-119               [64, 1024, 14, 14]   2,048\n",
       "|    |    + ReLU (relu): 3-120                     [64, 1024, 14, 14]   --\n",
       "+ Sequential (layer4): 1-8                         [64, 2048, 7, 7]     --\n",
       "|    + Bottleneck (0): 2-14                        [64, 2048, 7, 7]     --\n",
       "|    |    + Conv2d (conv1): 3-121                  [64, 1024, 14, 14]   1,048,576\n",
       "|    |    + BatchNorm2d (bn1): 3-122               [64, 1024, 14, 14]   2,048\n",
       "|    |    + ReLU (relu): 3-123                     [64, 1024, 14, 14]   --\n",
       "|    |    + Conv2d (conv2): 3-124                  [64, 1024, 7, 7]     294,912\n",
       "|    |    + BatchNorm2d (bn2): 3-125               [64, 1024, 7, 7]     2,048\n",
       "|    |    + ReLU (relu): 3-126                     [64, 1024, 7, 7]     --\n",
       "|    |    + Conv2d (conv3): 3-127                  [64, 2048, 7, 7]     2,097,152\n",
       "|    |    + BatchNorm2d (bn3): 3-128               [64, 2048, 7, 7]     4,096\n",
       "|    |    + Sequential (downsample): 3-129         [64, 2048, 7, 7]     2,101,248\n",
       "|    |    + ReLU (relu): 3-130                     [64, 2048, 7, 7]     --\n",
       "|    + Bottleneck (1): 2-15                        [64, 2048, 7, 7]     --\n",
       "|    |    + Conv2d (conv1): 3-131                  [64, 1024, 7, 7]     2,097,152\n",
       "|    |    + BatchNorm2d (bn1): 3-132               [64, 1024, 7, 7]     2,048\n",
       "|    |    + ReLU (relu): 3-133                     [64, 1024, 7, 7]     --\n",
       "|    |    + Conv2d (conv2): 3-134                  [64, 1024, 7, 7]     294,912\n",
       "|    |    + BatchNorm2d (bn2): 3-135               [64, 1024, 7, 7]     2,048\n",
       "|    |    + ReLU (relu): 3-136                     [64, 1024, 7, 7]     --\n",
       "|    |    + Conv2d (conv3): 3-137                  [64, 2048, 7, 7]     2,097,152\n",
       "|    |    + BatchNorm2d (bn3): 3-138               [64, 2048, 7, 7]     4,096\n",
       "|    |    + ReLU (relu): 3-139                     [64, 2048, 7, 7]     --\n",
       "|    + Bottleneck (2): 2-16                        [64, 2048, 7, 7]     --\n",
       "|    |    + Conv2d (conv1): 3-140                  [64, 1024, 7, 7]     2,097,152\n",
       "|    |    + BatchNorm2d (bn1): 3-141               [64, 1024, 7, 7]     2,048\n",
       "|    |    + ReLU (relu): 3-142                     [64, 1024, 7, 7]     --\n",
       "|    |    + Conv2d (conv2): 3-143                  [64, 1024, 7, 7]     294,912\n",
       "|    |    + BatchNorm2d (bn2): 3-144               [64, 1024, 7, 7]     2,048\n",
       "|    |    + ReLU (relu): 3-145                     [64, 1024, 7, 7]     --\n",
       "|    |    + Conv2d (conv3): 3-146                  [64, 2048, 7, 7]     2,097,152\n",
       "|    |    + BatchNorm2d (bn3): 3-147               [64, 2048, 7, 7]     4,096\n",
       "|    |    + ReLU (relu): 3-148                     [64, 2048, 7, 7]     --\n",
       "+ AdaptiveAvgPool2d (avgpool): 1-9                 [64, 2048, 1, 1]     --\n",
       "+ Linear (fc): 1-10                                [64, 1000]           2,049,000\n",
       "==========================================================================================\n",
       "Total params: 25,028,904\n",
       "Trainable params: 25,028,904\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 270.76\n",
       "==========================================================================================\n",
       "Input size (MB): 38.54\n",
       "Forward/backward pass size (MB): 14746.64\n",
       "Params size (MB): 100.12\n",
       "Estimated Total Size (MB): 14885.29\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torchvision.models.ResNeXt50_32X4D_Weights.DEFAULT\n",
    "model = torchvision.models.resnext50_32x4d(weights=weights).to(device)\n",
    "torchinfo.summary(\n",
    "    model=model,\n",
    "    input_size=(64,3,224,224),\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\", \"ascii_only\", \"depth\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000 40000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy\n",
    "\n",
    "\n",
    "auto_transform = weights.transforms()\n",
    "data = ImageFolderCustom(\n",
    "    targ_dir = data_path,\n",
    "    transform=auto_transform\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "total_samples=len(data)\n",
    "num_samples=200000\n",
    "\n",
    "\n",
    "indices=torch.tensor(numpy.random.permutation(numpy.arange(total_samples))[:num_samples])\n",
    "\n",
    "train_indices=indices[:int(0.8*num_samples)]\n",
    "test_indices=indices[int(0.8*num_samples):]\n",
    "\n",
    "train_dataset=Subset(data, train_indices)\n",
    "test_dataset=Subset(data, test_indices)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type (var_name))                  Output Shape         Param #\n",
       "================================================================================\n",
       "ResNet (ResNet)                          [64, 2]              --\n",
       "Conv2d (conv1)                         [64, 64, 112, 112]   9,408\n",
       "BatchNorm2d (bn1)                      [64, 64, 112, 112]   128\n",
       "ReLU (relu)                            [64, 64, 112, 112]   --\n",
       "MaxPool2d (maxpool)                    [64, 64, 56, 56]     --\n",
       "Sequential (layer1)                    [64, 256, 56, 56]    --\n",
       "    Bottleneck (0)                    [64, 256, 56, 56]    --\n",
       "        Conv2d (conv1)               [64, 128, 56, 56]    (8,192)\n",
       "        BatchNorm2d (bn1)            [64, 128, 56, 56]    (256)\n",
       "        ReLU (relu)                  [64, 128, 56, 56]    --\n",
       "        Conv2d (conv2)               [64, 128, 56, 56]    (4,608)\n",
       "        BatchNorm2d (bn2)            [64, 128, 56, 56]    (256)\n",
       "        ReLU (relu)                  [64, 128, 56, 56]    --\n",
       "        Conv2d (conv3)               [64, 256, 56, 56]    (32,768)\n",
       "        BatchNorm2d (bn3)            [64, 256, 56, 56]    (512)\n",
       "        Sequential (downsample)      [64, 256, 56, 56]    (16,896)\n",
       "        ReLU (relu)                  [64, 256, 56, 56]    --\n",
       "    Bottleneck (1)                    [64, 256, 56, 56]    --\n",
       "        Conv2d (conv1)               [64, 128, 56, 56]    (32,768)\n",
       "        BatchNorm2d (bn1)            [64, 128, 56, 56]    (256)\n",
       "        ReLU (relu)                  [64, 128, 56, 56]    --\n",
       "        Conv2d (conv2)               [64, 128, 56, 56]    (4,608)\n",
       "        BatchNorm2d (bn2)            [64, 128, 56, 56]    (256)\n",
       "        ReLU (relu)                  [64, 128, 56, 56]    --\n",
       "        Conv2d (conv3)               [64, 256, 56, 56]    (32,768)\n",
       "        BatchNorm2d (bn3)            [64, 256, 56, 56]    (512)\n",
       "        ReLU (relu)                  [64, 256, 56, 56]    --\n",
       "    Bottleneck (2)                    [64, 256, 56, 56]    --\n",
       "        Conv2d (conv1)               [64, 128, 56, 56]    (32,768)\n",
       "        BatchNorm2d (bn1)            [64, 128, 56, 56]    (256)\n",
       "        ReLU (relu)                  [64, 128, 56, 56]    --\n",
       "        Conv2d (conv2)               [64, 128, 56, 56]    (4,608)\n",
       "        BatchNorm2d (bn2)            [64, 128, 56, 56]    (256)\n",
       "        ReLU (relu)                  [64, 128, 56, 56]    --\n",
       "        Conv2d (conv3)               [64, 256, 56, 56]    (32,768)\n",
       "        BatchNorm2d (bn3)            [64, 256, 56, 56]    (512)\n",
       "        ReLU (relu)                  [64, 256, 56, 56]    --\n",
       "Sequential (layer2)                    [64, 512, 28, 28]    --\n",
       "    Bottleneck (0)                    [64, 512, 28, 28]    --\n",
       "        Conv2d (conv1)               [64, 256, 56, 56]    (65,536)\n",
       "        BatchNorm2d (bn1)            [64, 256, 56, 56]    (512)\n",
       "        ReLU (relu)                  [64, 256, 56, 56]    --\n",
       "        Conv2d (conv2)               [64, 256, 28, 28]    (18,432)\n",
       "        BatchNorm2d (bn2)            [64, 256, 28, 28]    (512)\n",
       "        ReLU (relu)                  [64, 256, 28, 28]    --\n",
       "        Conv2d (conv3)               [64, 512, 28, 28]    (131,072)\n",
       "        BatchNorm2d (bn3)            [64, 512, 28, 28]    (1,024)\n",
       "        Sequential (downsample)      [64, 512, 28, 28]    (132,096)\n",
       "        ReLU (relu)                  [64, 512, 28, 28]    --\n",
       "    Bottleneck (1)                    [64, 512, 28, 28]    --\n",
       "        Conv2d (conv1)               [64, 256, 28, 28]    (131,072)\n",
       "        BatchNorm2d (bn1)            [64, 256, 28, 28]    (512)\n",
       "        ReLU (relu)                  [64, 256, 28, 28]    --\n",
       "        Conv2d (conv2)               [64, 256, 28, 28]    (18,432)\n",
       "        BatchNorm2d (bn2)            [64, 256, 28, 28]    (512)\n",
       "        ReLU (relu)                  [64, 256, 28, 28]    --\n",
       "        Conv2d (conv3)               [64, 512, 28, 28]    (131,072)\n",
       "        BatchNorm2d (bn3)            [64, 512, 28, 28]    (1,024)\n",
       "        ReLU (relu)                  [64, 512, 28, 28]    --\n",
       "    Bottleneck (2)                    [64, 512, 28, 28]    --\n",
       "        Conv2d (conv1)               [64, 256, 28, 28]    (131,072)\n",
       "        BatchNorm2d (bn1)            [64, 256, 28, 28]    (512)\n",
       "        ReLU (relu)                  [64, 256, 28, 28]    --\n",
       "        Conv2d (conv2)               [64, 256, 28, 28]    (18,432)\n",
       "        BatchNorm2d (bn2)            [64, 256, 28, 28]    (512)\n",
       "        ReLU (relu)                  [64, 256, 28, 28]    --\n",
       "        Conv2d (conv3)               [64, 512, 28, 28]    (131,072)\n",
       "        BatchNorm2d (bn3)            [64, 512, 28, 28]    (1,024)\n",
       "        ReLU (relu)                  [64, 512, 28, 28]    --\n",
       "    Bottleneck (3)                    [64, 512, 28, 28]    --\n",
       "        Conv2d (conv1)               [64, 256, 28, 28]    (131,072)\n",
       "        BatchNorm2d (bn1)            [64, 256, 28, 28]    (512)\n",
       "        ReLU (relu)                  [64, 256, 28, 28]    --\n",
       "        Conv2d (conv2)               [64, 256, 28, 28]    (18,432)\n",
       "        BatchNorm2d (bn2)            [64, 256, 28, 28]    (512)\n",
       "        ReLU (relu)                  [64, 256, 28, 28]    --\n",
       "        Conv2d (conv3)               [64, 512, 28, 28]    (131,072)\n",
       "        BatchNorm2d (bn3)            [64, 512, 28, 28]    (1,024)\n",
       "        ReLU (relu)                  [64, 512, 28, 28]    --\n",
       "Sequential (layer3)                    [64, 1024, 14, 14]   --\n",
       "    Bottleneck (0)                    [64, 1024, 14, 14]   --\n",
       "        Conv2d (conv1)               [64, 512, 28, 28]    (262,144)\n",
       "        BatchNorm2d (bn1)            [64, 512, 28, 28]    (1,024)\n",
       "        ReLU (relu)                  [64, 512, 28, 28]    --\n",
       "        Conv2d (conv2)               [64, 512, 14, 14]    (73,728)\n",
       "        BatchNorm2d (bn2)            [64, 512, 14, 14]    (1,024)\n",
       "        ReLU (relu)                  [64, 512, 14, 14]    --\n",
       "        Conv2d (conv3)               [64, 1024, 14, 14]   (524,288)\n",
       "        BatchNorm2d (bn3)            [64, 1024, 14, 14]   (2,048)\n",
       "        Sequential (downsample)      [64, 1024, 14, 14]   (526,336)\n",
       "        ReLU (relu)                  [64, 1024, 14, 14]   --\n",
       "    Bottleneck (1)                    [64, 1024, 14, 14]   --\n",
       "        Conv2d (conv1)               [64, 512, 14, 14]    (524,288)\n",
       "        BatchNorm2d (bn1)            [64, 512, 14, 14]    (1,024)\n",
       "        ReLU (relu)                  [64, 512, 14, 14]    --\n",
       "        Conv2d (conv2)               [64, 512, 14, 14]    (73,728)\n",
       "        BatchNorm2d (bn2)            [64, 512, 14, 14]    (1,024)\n",
       "        ReLU (relu)                  [64, 512, 14, 14]    --\n",
       "        Conv2d (conv3)               [64, 1024, 14, 14]   (524,288)\n",
       "        BatchNorm2d (bn3)            [64, 1024, 14, 14]   (2,048)\n",
       "        ReLU (relu)                  [64, 1024, 14, 14]   --\n",
       "    Bottleneck (2)                    [64, 1024, 14, 14]   --\n",
       "        Conv2d (conv1)               [64, 512, 14, 14]    (524,288)\n",
       "        BatchNorm2d (bn1)            [64, 512, 14, 14]    (1,024)\n",
       "        ReLU (relu)                  [64, 512, 14, 14]    --\n",
       "        Conv2d (conv2)               [64, 512, 14, 14]    (73,728)\n",
       "        BatchNorm2d (bn2)            [64, 512, 14, 14]    (1,024)\n",
       "        ReLU (relu)                  [64, 512, 14, 14]    --\n",
       "        Conv2d (conv3)               [64, 1024, 14, 14]   (524,288)\n",
       "        BatchNorm2d (bn3)            [64, 1024, 14, 14]   (2,048)\n",
       "        ReLU (relu)                  [64, 1024, 14, 14]   --\n",
       "    Bottleneck (3)                    [64, 1024, 14, 14]   --\n",
       "        Conv2d (conv1)               [64, 512, 14, 14]    (524,288)\n",
       "        BatchNorm2d (bn1)            [64, 512, 14, 14]    (1,024)\n",
       "        ReLU (relu)                  [64, 512, 14, 14]    --\n",
       "        Conv2d (conv2)               [64, 512, 14, 14]    (73,728)\n",
       "        BatchNorm2d (bn2)            [64, 512, 14, 14]    (1,024)\n",
       "        ReLU (relu)                  [64, 512, 14, 14]    --\n",
       "        Conv2d (conv3)               [64, 1024, 14, 14]   (524,288)\n",
       "        BatchNorm2d (bn3)            [64, 1024, 14, 14]   (2,048)\n",
       "        ReLU (relu)                  [64, 1024, 14, 14]   --\n",
       "    Bottleneck (4)                    [64, 1024, 14, 14]   --\n",
       "        Conv2d (conv1)               [64, 512, 14, 14]    (524,288)\n",
       "        BatchNorm2d (bn1)            [64, 512, 14, 14]    (1,024)\n",
       "        ReLU (relu)                  [64, 512, 14, 14]    --\n",
       "        Conv2d (conv2)               [64, 512, 14, 14]    (73,728)\n",
       "        BatchNorm2d (bn2)            [64, 512, 14, 14]    (1,024)\n",
       "        ReLU (relu)                  [64, 512, 14, 14]    --\n",
       "        Conv2d (conv3)               [64, 1024, 14, 14]   (524,288)\n",
       "        BatchNorm2d (bn3)            [64, 1024, 14, 14]   (2,048)\n",
       "        ReLU (relu)                  [64, 1024, 14, 14]   --\n",
       "    Bottleneck (5)                    [64, 1024, 14, 14]   --\n",
       "        Conv2d (conv1)               [64, 512, 14, 14]    (524,288)\n",
       "        BatchNorm2d (bn1)            [64, 512, 14, 14]    (1,024)\n",
       "        ReLU (relu)                  [64, 512, 14, 14]    --\n",
       "        Conv2d (conv2)               [64, 512, 14, 14]    (73,728)\n",
       "        BatchNorm2d (bn2)            [64, 512, 14, 14]    (1,024)\n",
       "        ReLU (relu)                  [64, 512, 14, 14]    --\n",
       "        Conv2d (conv3)               [64, 1024, 14, 14]   (524,288)\n",
       "        BatchNorm2d (bn3)            [64, 1024, 14, 14]   (2,048)\n",
       "        ReLU (relu)                  [64, 1024, 14, 14]   --\n",
       "Sequential (layer4)                    [64, 2048, 7, 7]     --\n",
       "    Bottleneck (0)                    [64, 2048, 7, 7]     --\n",
       "        Conv2d (conv1)               [64, 1024, 14, 14]   1,048,576\n",
       "        BatchNorm2d (bn1)            [64, 1024, 14, 14]   2,048\n",
       "        ReLU (relu)                  [64, 1024, 14, 14]   --\n",
       "        Conv2d (conv2)               [64, 1024, 7, 7]     294,912\n",
       "        BatchNorm2d (bn2)            [64, 1024, 7, 7]     2,048\n",
       "        ReLU (relu)                  [64, 1024, 7, 7]     --\n",
       "        Conv2d (conv3)               [64, 2048, 7, 7]     2,097,152\n",
       "        BatchNorm2d (bn3)            [64, 2048, 7, 7]     4,096\n",
       "        Sequential (downsample)      [64, 2048, 7, 7]     2,101,248\n",
       "        ReLU (relu)                  [64, 2048, 7, 7]     --\n",
       "    Bottleneck (1)                    [64, 2048, 7, 7]     --\n",
       "        Conv2d (conv1)               [64, 1024, 7, 7]     2,097,152\n",
       "        BatchNorm2d (bn1)            [64, 1024, 7, 7]     2,048\n",
       "        ReLU (relu)                  [64, 1024, 7, 7]     --\n",
       "        Conv2d (conv2)               [64, 1024, 7, 7]     294,912\n",
       "        BatchNorm2d (bn2)            [64, 1024, 7, 7]     2,048\n",
       "        ReLU (relu)                  [64, 1024, 7, 7]     --\n",
       "        Conv2d (conv3)               [64, 2048, 7, 7]     2,097,152\n",
       "        BatchNorm2d (bn3)            [64, 2048, 7, 7]     4,096\n",
       "        ReLU (relu)                  [64, 2048, 7, 7]     --\n",
       "    Bottleneck (2)                    [64, 2048, 7, 7]     --\n",
       "        Conv2d (conv1)               [64, 1024, 7, 7]     2,097,152\n",
       "        BatchNorm2d (bn1)            [64, 1024, 7, 7]     2,048\n",
       "        ReLU (relu)                  [64, 1024, 7, 7]     --\n",
       "        Conv2d (conv2)               [64, 1024, 7, 7]     294,912\n",
       "        BatchNorm2d (bn2)            [64, 1024, 7, 7]     2,048\n",
       "        ReLU (relu)                  [64, 1024, 7, 7]     --\n",
       "        Conv2d (conv3)               [64, 2048, 7, 7]     2,097,152\n",
       "        BatchNorm2d (bn3)            [64, 2048, 7, 7]     4,096\n",
       "        ReLU (relu)                  [64, 2048, 7, 7]     --\n",
       "AdaptiveAvgPool2d (avgpool)            [64, 2048, 1, 1]     --\n",
       "Sequential (fc)                        [64, 2]              --\n",
       "    Dropout (0)                       [64, 2048]           --\n",
       "    Linear (1)                        [64, 2]              4,098\n",
       "================================================================================\n",
       "Total params: 22,984,002\n",
       "Trainable params: 14,558,530\n",
       "Non-trainable params: 8,425,472\n",
       "Total mult-adds (G): 270.62\n",
       "================================================================================\n",
       "Input size (MB): 38.54\n",
       "Forward/backward pass size (MB): 14746.13\n",
       "Params size (MB): 91.94\n",
       "Estimated Total Size (MB): 14876.60\n",
       "================================================================================"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.layer1.parameters():\n",
    "    param.requires_grad=False\n",
    "for param in model.layer2.parameters():\n",
    "    param.requires_grad=False\n",
    "for param in model.layer3.parameters():\n",
    "    param.requires_grad=False\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad=True\n",
    "\n",
    "output_shape = len(data.classes)\n",
    "\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=2048, out_features=output_shape)\n",
    ").to(device)\n",
    "\n",
    "torchinfo.summary(\n",
    "    model=model,\n",
    "    input_size=(64,3,224,224),\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 1/10 [09:21<1:24:13, 561.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.2057 | train_acc: 0.9223 | test_loss: 11.3081 | test_acc: 0.9324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 2/10 [18:35<1:14:16, 557.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.1616 | train_acc: 0.9394 | test_loss: 15.2946 | test_acc: 0.9402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 3/10 [27:50<1:04:53, 556.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.1440 | train_acc: 0.9465 | test_loss: 15.6275 | test_acc: 0.9438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 4/10 [37:04<55:32, 555.35s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.1278 | train_acc: 0.9518 | test_loss: 874.6698 | test_acc: 0.9423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 5/10 [46:20<46:17, 555.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.1103 | train_acc: 0.9586 | test_loss: 139.4730 | test_acc: 0.9455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 6/10 [55:36<37:02, 555.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | train_loss: 0.0928 | train_acc: 0.9655 | test_loss: 308.6692 | test_acc: 0.9405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 7/10 [1:04:52<27:47, 555.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | train_loss: 0.0750 | train_acc: 0.9719 | test_loss: 231.0987 | test_acc: 0.9457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 8/10 [1:14:05<18:30, 555.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | train_loss: 0.0617 | train_acc: 0.9777 | test_loss: 59.2396 | test_acc: 0.9445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 9/10 [1:23:20<09:14, 554.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | train_loss: 0.0515 | train_acc: 0.9815 | test_loss: 16.7924 | test_acc: 0.9443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [1:32:33<00:00, 555.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | train_loss: 0.0443 | train_acc: 0.9839 | test_loss: 45.5379 | test_acc: 0.9415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=10,\n",
    "    device=device,\n",
    "    writer=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = Path(\"models/ResNeXt-50-32x4d_200k.pt\")\n",
    "torch.save(obj=model.state_dict(), f=SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet-169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type (var_name):depth-idx)                  Output Shape         Param #\n",
       "==========================================================================================\n",
       "DenseNet (DenseNet)                                [64, 1000]           --\n",
       "+ Sequential (features): 1-1                       [64, 1664, 8, 8]     --\n",
       "|    + Conv2d (conv0): 2-1                         [64, 64, 128, 128]   9,408\n",
       "|    + BatchNorm2d (norm0): 2-2                    [64, 64, 128, 128]   128\n",
       "|    + ReLU (relu0): 2-3                           [64, 64, 128, 128]   --\n",
       "|    + MaxPool2d (pool0): 2-4                      [64, 64, 64, 64]     --\n",
       "|    + _DenseBlock (denseblock1): 2-5              [64, 256, 64, 64]    --\n",
       "|    |    + _DenseLayer (denselayer1): 3-1         [64, 32, 64, 64]     45,440\n",
       "|    |    + _DenseLayer (denselayer2): 3-2         [64, 32, 64, 64]     49,600\n",
       "|    |    + _DenseLayer (denselayer3): 3-3         [64, 32, 64, 64]     53,760\n",
       "|    |    + _DenseLayer (denselayer4): 3-4         [64, 32, 64, 64]     57,920\n",
       "|    |    + _DenseLayer (denselayer5): 3-5         [64, 32, 64, 64]     62,080\n",
       "|    |    + _DenseLayer (denselayer6): 3-6         [64, 32, 64, 64]     66,240\n",
       "|    + _Transition (transition1): 2-6              [64, 128, 32, 32]    --\n",
       "|    |    + BatchNorm2d (norm): 3-7                [64, 256, 64, 64]    512\n",
       "|    |    + ReLU (relu): 3-8                       [64, 256, 64, 64]    --\n",
       "|    |    + Conv2d (conv): 3-9                     [64, 128, 64, 64]    32,768\n",
       "|    |    + AvgPool2d (pool): 3-10                 [64, 128, 32, 32]    --\n",
       "|    + _DenseBlock (denseblock2): 2-7              [64, 512, 32, 32]    --\n",
       "|    |    + _DenseLayer (denselayer1): 3-11        [64, 32, 32, 32]     53,760\n",
       "|    |    + _DenseLayer (denselayer2): 3-12        [64, 32, 32, 32]     57,920\n",
       "|    |    + _DenseLayer (denselayer3): 3-13        [64, 32, 32, 32]     62,080\n",
       "|    |    + _DenseLayer (denselayer4): 3-14        [64, 32, 32, 32]     66,240\n",
       "|    |    + _DenseLayer (denselayer5): 3-15        [64, 32, 32, 32]     70,400\n",
       "|    |    + _DenseLayer (denselayer6): 3-16        [64, 32, 32, 32]     74,560\n",
       "|    |    + _DenseLayer (denselayer7): 3-17        [64, 32, 32, 32]     78,720\n",
       "|    |    + _DenseLayer (denselayer8): 3-18        [64, 32, 32, 32]     82,880\n",
       "|    |    + _DenseLayer (denselayer9): 3-19        [64, 32, 32, 32]     87,040\n",
       "|    |    + _DenseLayer (denselayer10): 3-20       [64, 32, 32, 32]     91,200\n",
       "|    |    + _DenseLayer (denselayer11): 3-21       [64, 32, 32, 32]     95,360\n",
       "|    |    + _DenseLayer (denselayer12): 3-22       [64, 32, 32, 32]     99,520\n",
       "|    + _Transition (transition2): 2-8              [64, 256, 16, 16]    --\n",
       "|    |    + BatchNorm2d (norm): 3-23               [64, 512, 32, 32]    1,024\n",
       "|    |    + ReLU (relu): 3-24                      [64, 512, 32, 32]    --\n",
       "|    |    + Conv2d (conv): 3-25                    [64, 256, 32, 32]    131,072\n",
       "|    |    + AvgPool2d (pool): 3-26                 [64, 256, 16, 16]    --\n",
       "|    + _DenseBlock (denseblock3): 2-9              [64, 1280, 16, 16]   --\n",
       "|    |    + _DenseLayer (denselayer1): 3-27        [64, 32, 16, 16]     70,400\n",
       "|    |    + _DenseLayer (denselayer2): 3-28        [64, 32, 16, 16]     74,560\n",
       "|    |    + _DenseLayer (denselayer3): 3-29        [64, 32, 16, 16]     78,720\n",
       "|    |    + _DenseLayer (denselayer4): 3-30        [64, 32, 16, 16]     82,880\n",
       "|    |    + _DenseLayer (denselayer5): 3-31        [64, 32, 16, 16]     87,040\n",
       "|    |    + _DenseLayer (denselayer6): 3-32        [64, 32, 16, 16]     91,200\n",
       "|    |    + _DenseLayer (denselayer7): 3-33        [64, 32, 16, 16]     95,360\n",
       "|    |    + _DenseLayer (denselayer8): 3-34        [64, 32, 16, 16]     99,520\n",
       "|    |    + _DenseLayer (denselayer9): 3-35        [64, 32, 16, 16]     103,680\n",
       "|    |    + _DenseLayer (denselayer10): 3-36       [64, 32, 16, 16]     107,840\n",
       "|    |    + _DenseLayer (denselayer11): 3-37       [64, 32, 16, 16]     112,000\n",
       "|    |    + _DenseLayer (denselayer12): 3-38       [64, 32, 16, 16]     116,160\n",
       "|    |    + _DenseLayer (denselayer13): 3-39       [64, 32, 16, 16]     120,320\n",
       "|    |    + _DenseLayer (denselayer14): 3-40       [64, 32, 16, 16]     124,480\n",
       "|    |    + _DenseLayer (denselayer15): 3-41       [64, 32, 16, 16]     128,640\n",
       "|    |    + _DenseLayer (denselayer16): 3-42       [64, 32, 16, 16]     132,800\n",
       "|    |    + _DenseLayer (denselayer17): 3-43       [64, 32, 16, 16]     136,960\n",
       "|    |    + _DenseLayer (denselayer18): 3-44       [64, 32, 16, 16]     141,120\n",
       "|    |    + _DenseLayer (denselayer19): 3-45       [64, 32, 16, 16]     145,280\n",
       "|    |    + _DenseLayer (denselayer20): 3-46       [64, 32, 16, 16]     149,440\n",
       "|    |    + _DenseLayer (denselayer21): 3-47       [64, 32, 16, 16]     153,600\n",
       "|    |    + _DenseLayer (denselayer22): 3-48       [64, 32, 16, 16]     157,760\n",
       "|    |    + _DenseLayer (denselayer23): 3-49       [64, 32, 16, 16]     161,920\n",
       "|    |    + _DenseLayer (denselayer24): 3-50       [64, 32, 16, 16]     166,080\n",
       "|    |    + _DenseLayer (denselayer25): 3-51       [64, 32, 16, 16]     170,240\n",
       "|    |    + _DenseLayer (denselayer26): 3-52       [64, 32, 16, 16]     174,400\n",
       "|    |    + _DenseLayer (denselayer27): 3-53       [64, 32, 16, 16]     178,560\n",
       "|    |    + _DenseLayer (denselayer28): 3-54       [64, 32, 16, 16]     182,720\n",
       "|    |    + _DenseLayer (denselayer29): 3-55       [64, 32, 16, 16]     186,880\n",
       "|    |    + _DenseLayer (denselayer30): 3-56       [64, 32, 16, 16]     191,040\n",
       "|    |    + _DenseLayer (denselayer31): 3-57       [64, 32, 16, 16]     195,200\n",
       "|    |    + _DenseLayer (denselayer32): 3-58       [64, 32, 16, 16]     199,360\n",
       "|    + _Transition (transition3): 2-10             [64, 640, 8, 8]      --\n",
       "|    |    + BatchNorm2d (norm): 3-59               [64, 1280, 16, 16]   2,560\n",
       "|    |    + ReLU (relu): 3-60                      [64, 1280, 16, 16]   --\n",
       "|    |    + Conv2d (conv): 3-61                    [64, 640, 16, 16]    819,200\n",
       "|    |    + AvgPool2d (pool): 3-62                 [64, 640, 8, 8]      --\n",
       "|    + _DenseBlock (denseblock4): 2-11             [64, 1664, 8, 8]     --\n",
       "|    |    + _DenseLayer (denselayer1): 3-63        [64, 32, 8, 8]       120,320\n",
       "|    |    + _DenseLayer (denselayer2): 3-64        [64, 32, 8, 8]       124,480\n",
       "|    |    + _DenseLayer (denselayer3): 3-65        [64, 32, 8, 8]       128,640\n",
       "|    |    + _DenseLayer (denselayer4): 3-66        [64, 32, 8, 8]       132,800\n",
       "|    |    + _DenseLayer (denselayer5): 3-67        [64, 32, 8, 8]       136,960\n",
       "|    |    + _DenseLayer (denselayer6): 3-68        [64, 32, 8, 8]       141,120\n",
       "|    |    + _DenseLayer (denselayer7): 3-69        [64, 32, 8, 8]       145,280\n",
       "|    |    + _DenseLayer (denselayer8): 3-70        [64, 32, 8, 8]       149,440\n",
       "|    |    + _DenseLayer (denselayer9): 3-71        [64, 32, 8, 8]       153,600\n",
       "|    |    + _DenseLayer (denselayer10): 3-72       [64, 32, 8, 8]       157,760\n",
       "|    |    + _DenseLayer (denselayer11): 3-73       [64, 32, 8, 8]       161,920\n",
       "|    |    + _DenseLayer (denselayer12): 3-74       [64, 32, 8, 8]       166,080\n",
       "|    |    + _DenseLayer (denselayer13): 3-75       [64, 32, 8, 8]       170,240\n",
       "|    |    + _DenseLayer (denselayer14): 3-76       [64, 32, 8, 8]       174,400\n",
       "|    |    + _DenseLayer (denselayer15): 3-77       [64, 32, 8, 8]       178,560\n",
       "|    |    + _DenseLayer (denselayer16): 3-78       [64, 32, 8, 8]       182,720\n",
       "|    |    + _DenseLayer (denselayer17): 3-79       [64, 32, 8, 8]       186,880\n",
       "|    |    + _DenseLayer (denselayer18): 3-80       [64, 32, 8, 8]       191,040\n",
       "|    |    + _DenseLayer (denselayer19): 3-81       [64, 32, 8, 8]       195,200\n",
       "|    |    + _DenseLayer (denselayer20): 3-82       [64, 32, 8, 8]       199,360\n",
       "|    |    + _DenseLayer (denselayer21): 3-83       [64, 32, 8, 8]       203,520\n",
       "|    |    + _DenseLayer (denselayer22): 3-84       [64, 32, 8, 8]       207,680\n",
       "|    |    + _DenseLayer (denselayer23): 3-85       [64, 32, 8, 8]       211,840\n",
       "|    |    + _DenseLayer (denselayer24): 3-86       [64, 32, 8, 8]       216,000\n",
       "|    |    + _DenseLayer (denselayer25): 3-87       [64, 32, 8, 8]       220,160\n",
       "|    |    + _DenseLayer (denselayer26): 3-88       [64, 32, 8, 8]       224,320\n",
       "|    |    + _DenseLayer (denselayer27): 3-89       [64, 32, 8, 8]       228,480\n",
       "|    |    + _DenseLayer (denselayer28): 3-90       [64, 32, 8, 8]       232,640\n",
       "|    |    + _DenseLayer (denselayer29): 3-91       [64, 32, 8, 8]       236,800\n",
       "|    |    + _DenseLayer (denselayer30): 3-92       [64, 32, 8, 8]       240,960\n",
       "|    |    + _DenseLayer (denselayer31): 3-93       [64, 32, 8, 8]       245,120\n",
       "|    |    + _DenseLayer (denselayer32): 3-94       [64, 32, 8, 8]       249,280\n",
       "|    + BatchNorm2d (norm5): 2-12                   [64, 1664, 8, 8]     3,328\n",
       "+ Linear (classifier): 1-2                         [64, 1000]           1,665,000\n",
       "==========================================================================================\n",
       "Total params: 14,149,480\n",
       "Trainable params: 14,149,480\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 280.83\n",
       "==========================================================================================\n",
       "Input size (MB): 50.33\n",
       "Forward/backward pass size (MB): 17604.01\n",
       "Params size (MB): 56.60\n",
       "Estimated Total Size (MB): 17710.94\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torchvision.models.DenseNet169_Weights.DEFAULT\n",
    "model = torchvision.models.densenet169(weights=weights).to(device)\n",
    "torchinfo.summary(\n",
    "    model=model,\n",
    "    input_size=(64,3,256,256),\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\", \"ascii_only\", \"depth\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 20000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy\n",
    "\n",
    "\n",
    "auto_transform = weights.transforms()\n",
    "data = ImageFolderCustom(\n",
    "    targ_dir = data_path,\n",
    "    transform=auto_transform\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "total_samples=len(data)\n",
    "num_samples=100000\n",
    "\n",
    "\n",
    "indices=torch.tensor(numpy.random.permutation(numpy.arange(total_samples))[:num_samples])\n",
    "\n",
    "train_indices=indices[:int(0.8*num_samples)]\n",
    "test_indices=indices[int(0.8*num_samples):]\n",
    "\n",
    "train_dataset=Subset(data, train_indices)\n",
    "test_dataset=Subset(data, test_indices)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type (var_name))                       Output Shape              Param #\n",
       "===============================================================================================\n",
       "DenseNet (DenseNet)                           [64, 2]                   --\n",
       "Sequential (features)                       [64, 1664, 8, 8]          --\n",
       "    Conv2d (conv0)                         [64, 64, 128, 128]        9,408\n",
       "    BatchNorm2d (norm0)                    [64, 64, 128, 128]        128\n",
       "    ReLU (relu0)                           [64, 64, 128, 128]        --\n",
       "    MaxPool2d (pool0)                      [64, 64, 64, 64]          --\n",
       "    _DenseBlock (denseblock1)              [64, 256, 64, 64]         --\n",
       "        _DenseLayer (denselayer1)         [64, 32, 64, 64]          45,440\n",
       "        _DenseLayer (denselayer2)         [64, 32, 64, 64]          49,600\n",
       "        _DenseLayer (denselayer3)         [64, 32, 64, 64]          53,760\n",
       "        _DenseLayer (denselayer4)         [64, 32, 64, 64]          57,920\n",
       "        _DenseLayer (denselayer5)         [64, 32, 64, 64]          62,080\n",
       "        _DenseLayer (denselayer6)         [64, 32, 64, 64]          66,240\n",
       "    _Transition (transition1)              [64, 128, 32, 32]         --\n",
       "        BatchNorm2d (norm)                [64, 256, 64, 64]         512\n",
       "        ReLU (relu)                       [64, 256, 64, 64]         --\n",
       "        Conv2d (conv)                     [64, 128, 64, 64]         32,768\n",
       "        AvgPool2d (pool)                  [64, 128, 32, 32]         --\n",
       "    _DenseBlock (denseblock2)              [64, 512, 32, 32]         --\n",
       "        _DenseLayer (denselayer1)         [64, 32, 32, 32]          53,760\n",
       "        _DenseLayer (denselayer2)         [64, 32, 32, 32]          57,920\n",
       "        _DenseLayer (denselayer3)         [64, 32, 32, 32]          62,080\n",
       "        _DenseLayer (denselayer4)         [64, 32, 32, 32]          66,240\n",
       "        _DenseLayer (denselayer5)         [64, 32, 32, 32]          70,400\n",
       "        _DenseLayer (denselayer6)         [64, 32, 32, 32]          74,560\n",
       "        _DenseLayer (denselayer7)         [64, 32, 32, 32]          78,720\n",
       "        _DenseLayer (denselayer8)         [64, 32, 32, 32]          82,880\n",
       "        _DenseLayer (denselayer9)         [64, 32, 32, 32]          87,040\n",
       "        _DenseLayer (denselayer10)        [64, 32, 32, 32]          91,200\n",
       "        _DenseLayer (denselayer11)        [64, 32, 32, 32]          95,360\n",
       "        _DenseLayer (denselayer12)        [64, 32, 32, 32]          99,520\n",
       "    _Transition (transition2)              [64, 256, 16, 16]         --\n",
       "        BatchNorm2d (norm)                [64, 512, 32, 32]         1,024\n",
       "        ReLU (relu)                       [64, 512, 32, 32]         --\n",
       "        Conv2d (conv)                     [64, 256, 32, 32]         131,072\n",
       "        AvgPool2d (pool)                  [64, 256, 16, 16]         --\n",
       "    _DenseBlock (denseblock3)              [64, 1280, 16, 16]        --\n",
       "        _DenseLayer (denselayer1)         [64, 32, 16, 16]          70,400\n",
       "        _DenseLayer (denselayer2)         [64, 32, 16, 16]          74,560\n",
       "        _DenseLayer (denselayer3)         [64, 32, 16, 16]          78,720\n",
       "        _DenseLayer (denselayer4)         [64, 32, 16, 16]          82,880\n",
       "        _DenseLayer (denselayer5)         [64, 32, 16, 16]          87,040\n",
       "        _DenseLayer (denselayer6)         [64, 32, 16, 16]          91,200\n",
       "        _DenseLayer (denselayer7)         [64, 32, 16, 16]          95,360\n",
       "        _DenseLayer (denselayer8)         [64, 32, 16, 16]          99,520\n",
       "        _DenseLayer (denselayer9)         [64, 32, 16, 16]          103,680\n",
       "        _DenseLayer (denselayer10)        [64, 32, 16, 16]          107,840\n",
       "        _DenseLayer (denselayer11)        [64, 32, 16, 16]          112,000\n",
       "        _DenseLayer (denselayer12)        [64, 32, 16, 16]          116,160\n",
       "        _DenseLayer (denselayer13)        [64, 32, 16, 16]          120,320\n",
       "        _DenseLayer (denselayer14)        [64, 32, 16, 16]          124,480\n",
       "        _DenseLayer (denselayer15)        [64, 32, 16, 16]          128,640\n",
       "        _DenseLayer (denselayer16)        [64, 32, 16, 16]          132,800\n",
       "        _DenseLayer (denselayer17)        [64, 32, 16, 16]          136,960\n",
       "        _DenseLayer (denselayer18)        [64, 32, 16, 16]          141,120\n",
       "        _DenseLayer (denselayer19)        [64, 32, 16, 16]          145,280\n",
       "        _DenseLayer (denselayer20)        [64, 32, 16, 16]          149,440\n",
       "        _DenseLayer (denselayer21)        [64, 32, 16, 16]          153,600\n",
       "        _DenseLayer (denselayer22)        [64, 32, 16, 16]          157,760\n",
       "        _DenseLayer (denselayer23)        [64, 32, 16, 16]          161,920\n",
       "        _DenseLayer (denselayer24)        [64, 32, 16, 16]          166,080\n",
       "        _DenseLayer (denselayer25)        [64, 32, 16, 16]          170,240\n",
       "        _DenseLayer (denselayer26)        [64, 32, 16, 16]          174,400\n",
       "        _DenseLayer (denselayer27)        [64, 32, 16, 16]          178,560\n",
       "        _DenseLayer (denselayer28)        [64, 32, 16, 16]          182,720\n",
       "        _DenseLayer (denselayer29)        [64, 32, 16, 16]          186,880\n",
       "        _DenseLayer (denselayer30)        [64, 32, 16, 16]          191,040\n",
       "        _DenseLayer (denselayer31)        [64, 32, 16, 16]          195,200\n",
       "        _DenseLayer (denselayer32)        [64, 32, 16, 16]          199,360\n",
       "    _Transition (transition3)              [64, 640, 8, 8]           --\n",
       "        BatchNorm2d (norm)                [64, 1280, 16, 16]        2,560\n",
       "        ReLU (relu)                       [64, 1280, 16, 16]        --\n",
       "        Conv2d (conv)                     [64, 640, 16, 16]         819,200\n",
       "        AvgPool2d (pool)                  [64, 640, 8, 8]           --\n",
       "    _DenseBlock (denseblock4)              [64, 1664, 8, 8]          --\n",
       "        _DenseLayer (denselayer1)         [64, 32, 8, 8]            120,320\n",
       "        _DenseLayer (denselayer2)         [64, 32, 8, 8]            124,480\n",
       "        _DenseLayer (denselayer3)         [64, 32, 8, 8]            128,640\n",
       "        _DenseLayer (denselayer4)         [64, 32, 8, 8]            132,800\n",
       "        _DenseLayer (denselayer5)         [64, 32, 8, 8]            136,960\n",
       "        _DenseLayer (denselayer6)         [64, 32, 8, 8]            141,120\n",
       "        _DenseLayer (denselayer7)         [64, 32, 8, 8]            145,280\n",
       "        _DenseLayer (denselayer8)         [64, 32, 8, 8]            149,440\n",
       "        _DenseLayer (denselayer9)         [64, 32, 8, 8]            153,600\n",
       "        _DenseLayer (denselayer10)        [64, 32, 8, 8]            157,760\n",
       "        _DenseLayer (denselayer11)        [64, 32, 8, 8]            161,920\n",
       "        _DenseLayer (denselayer12)        [64, 32, 8, 8]            166,080\n",
       "        _DenseLayer (denselayer13)        [64, 32, 8, 8]            170,240\n",
       "        _DenseLayer (denselayer14)        [64, 32, 8, 8]            174,400\n",
       "        _DenseLayer (denselayer15)        [64, 32, 8, 8]            178,560\n",
       "        _DenseLayer (denselayer16)        [64, 32, 8, 8]            182,720\n",
       "        _DenseLayer (denselayer17)        [64, 32, 8, 8]            186,880\n",
       "        _DenseLayer (denselayer18)        [64, 32, 8, 8]            191,040\n",
       "        _DenseLayer (denselayer19)        [64, 32, 8, 8]            195,200\n",
       "        _DenseLayer (denselayer20)        [64, 32, 8, 8]            199,360\n",
       "        _DenseLayer (denselayer21)        [64, 32, 8, 8]            203,520\n",
       "        _DenseLayer (denselayer22)        [64, 32, 8, 8]            207,680\n",
       "        _DenseLayer (denselayer23)        [64, 32, 8, 8]            211,840\n",
       "        _DenseLayer (denselayer24)        [64, 32, 8, 8]            216,000\n",
       "        _DenseLayer (denselayer25)        [64, 32, 8, 8]            220,160\n",
       "        _DenseLayer (denselayer26)        [64, 32, 8, 8]            224,320\n",
       "        _DenseLayer (denselayer27)        [64, 32, 8, 8]            228,480\n",
       "        _DenseLayer (denselayer28)        [64, 32, 8, 8]            232,640\n",
       "        _DenseLayer (denselayer29)        [64, 32, 8, 8]            236,800\n",
       "        _DenseLayer (denselayer30)        [64, 32, 8, 8]            240,960\n",
       "        _DenseLayer (denselayer31)        [64, 32, 8, 8]            245,120\n",
       "        _DenseLayer (denselayer32)        [64, 32, 8, 8]            249,280\n",
       "    BatchNorm2d (norm5)                    [64, 1664, 8, 8]          3,328\n",
       "Sequential (classifier)                     [64, 2]                   --\n",
       "    Linear (0)                             [64, 2]                   3,330\n",
       "===============================================================================================\n",
       "Total params: 12,487,810\n",
       "Trainable params: 12,487,810\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 280.73\n",
       "===============================================================================================\n",
       "Input size (MB): 50.33\n",
       "Forward/backward pass size (MB): 17603.49\n",
       "Params size (MB): 49.95\n",
       "Estimated Total Size (MB): 17703.78\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape = len(data.classes)\n",
    "\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=1664, out_features=output_shape)\n",
    ").to(device)\n",
    "\n",
    "torchinfo.summary(\n",
    "    model=model,\n",
    "    input_size=(64,3,256,256),\n",
    "    # col_width=20,\n",
    "    row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 1/5 [07:32<30:10, 452.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.2857 | train_acc: 0.8866 | test_loss: 0.2335 | test_acc: 0.9152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 2/5 [15:04<22:37, 452.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.2327 | train_acc: 0.9092 | test_loss: 0.2321 | test_acc: 0.9106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 3/5 [22:37<15:04, 452.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.2151 | train_acc: 0.9179 | test_loss: 0.2005 | test_acc: 0.9217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 4/5 [30:08<07:31, 451.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.1936 | train_acc: 0.9270 | test_loss: 0.1709 | test_acc: 0.9334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [37:49<00:00, 453.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.1772 | train_acc: 0.9326 | test_loss: 0.2659 | test_acc: 0.8892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=5,\n",
    "    device=device,\n",
    "    writer=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = Path(\"models/DenseNet-169_100k.pt\")\n",
    "torch.save(obj=model.state_dict(), f=SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DENSENET-121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type (var_name):depth-idx)                  Output Shape         Param #\n",
       "==========================================================================================\n",
       "DenseNet (DenseNet)                                [64, 1000]           --\n",
       "+ Sequential (features): 1-1                       [64, 1024, 8, 8]     --\n",
       "|    + Conv2d (conv0): 2-1                         [64, 64, 128, 128]   9,408\n",
       "|    + BatchNorm2d (norm0): 2-2                    [64, 64, 128, 128]   128\n",
       "|    + ReLU (relu0): 2-3                           [64, 64, 128, 128]   --\n",
       "|    + MaxPool2d (pool0): 2-4                      [64, 64, 64, 64]     --\n",
       "|    + _DenseBlock (denseblock1): 2-5              [64, 256, 64, 64]    --\n",
       "|    |    + _DenseLayer (denselayer1): 3-1         [64, 32, 64, 64]     45,440\n",
       "|    |    + _DenseLayer (denselayer2): 3-2         [64, 32, 64, 64]     49,600\n",
       "|    |    + _DenseLayer (denselayer3): 3-3         [64, 32, 64, 64]     53,760\n",
       "|    |    + _DenseLayer (denselayer4): 3-4         [64, 32, 64, 64]     57,920\n",
       "|    |    + _DenseLayer (denselayer5): 3-5         [64, 32, 64, 64]     62,080\n",
       "|    |    + _DenseLayer (denselayer6): 3-6         [64, 32, 64, 64]     66,240\n",
       "|    + _Transition (transition1): 2-6              [64, 128, 32, 32]    --\n",
       "|    |    + BatchNorm2d (norm): 3-7                [64, 256, 64, 64]    512\n",
       "|    |    + ReLU (relu): 3-8                       [64, 256, 64, 64]    --\n",
       "|    |    + Conv2d (conv): 3-9                     [64, 128, 64, 64]    32,768\n",
       "|    |    + AvgPool2d (pool): 3-10                 [64, 128, 32, 32]    --\n",
       "|    + _DenseBlock (denseblock2): 2-7              [64, 512, 32, 32]    --\n",
       "|    |    + _DenseLayer (denselayer1): 3-11        [64, 32, 32, 32]     53,760\n",
       "|    |    + _DenseLayer (denselayer2): 3-12        [64, 32, 32, 32]     57,920\n",
       "|    |    + _DenseLayer (denselayer3): 3-13        [64, 32, 32, 32]     62,080\n",
       "|    |    + _DenseLayer (denselayer4): 3-14        [64, 32, 32, 32]     66,240\n",
       "|    |    + _DenseLayer (denselayer5): 3-15        [64, 32, 32, 32]     70,400\n",
       "|    |    + _DenseLayer (denselayer6): 3-16        [64, 32, 32, 32]     74,560\n",
       "|    |    + _DenseLayer (denselayer7): 3-17        [64, 32, 32, 32]     78,720\n",
       "|    |    + _DenseLayer (denselayer8): 3-18        [64, 32, 32, 32]     82,880\n",
       "|    |    + _DenseLayer (denselayer9): 3-19        [64, 32, 32, 32]     87,040\n",
       "|    |    + _DenseLayer (denselayer10): 3-20       [64, 32, 32, 32]     91,200\n",
       "|    |    + _DenseLayer (denselayer11): 3-21       [64, 32, 32, 32]     95,360\n",
       "|    |    + _DenseLayer (denselayer12): 3-22       [64, 32, 32, 32]     99,520\n",
       "|    + _Transition (transition2): 2-8              [64, 256, 16, 16]    --\n",
       "|    |    + BatchNorm2d (norm): 3-23               [64, 512, 32, 32]    1,024\n",
       "|    |    + ReLU (relu): 3-24                      [64, 512, 32, 32]    --\n",
       "|    |    + Conv2d (conv): 3-25                    [64, 256, 32, 32]    131,072\n",
       "|    |    + AvgPool2d (pool): 3-26                 [64, 256, 16, 16]    --\n",
       "|    + _DenseBlock (denseblock3): 2-9              [64, 1024, 16, 16]   --\n",
       "|    |    + _DenseLayer (denselayer1): 3-27        [64, 32, 16, 16]     70,400\n",
       "|    |    + _DenseLayer (denselayer2): 3-28        [64, 32, 16, 16]     74,560\n",
       "|    |    + _DenseLayer (denselayer3): 3-29        [64, 32, 16, 16]     78,720\n",
       "|    |    + _DenseLayer (denselayer4): 3-30        [64, 32, 16, 16]     82,880\n",
       "|    |    + _DenseLayer (denselayer5): 3-31        [64, 32, 16, 16]     87,040\n",
       "|    |    + _DenseLayer (denselayer6): 3-32        [64, 32, 16, 16]     91,200\n",
       "|    |    + _DenseLayer (denselayer7): 3-33        [64, 32, 16, 16]     95,360\n",
       "|    |    + _DenseLayer (denselayer8): 3-34        [64, 32, 16, 16]     99,520\n",
       "|    |    + _DenseLayer (denselayer9): 3-35        [64, 32, 16, 16]     103,680\n",
       "|    |    + _DenseLayer (denselayer10): 3-36       [64, 32, 16, 16]     107,840\n",
       "|    |    + _DenseLayer (denselayer11): 3-37       [64, 32, 16, 16]     112,000\n",
       "|    |    + _DenseLayer (denselayer12): 3-38       [64, 32, 16, 16]     116,160\n",
       "|    |    + _DenseLayer (denselayer13): 3-39       [64, 32, 16, 16]     120,320\n",
       "|    |    + _DenseLayer (denselayer14): 3-40       [64, 32, 16, 16]     124,480\n",
       "|    |    + _DenseLayer (denselayer15): 3-41       [64, 32, 16, 16]     128,640\n",
       "|    |    + _DenseLayer (denselayer16): 3-42       [64, 32, 16, 16]     132,800\n",
       "|    |    + _DenseLayer (denselayer17): 3-43       [64, 32, 16, 16]     136,960\n",
       "|    |    + _DenseLayer (denselayer18): 3-44       [64, 32, 16, 16]     141,120\n",
       "|    |    + _DenseLayer (denselayer19): 3-45       [64, 32, 16, 16]     145,280\n",
       "|    |    + _DenseLayer (denselayer20): 3-46       [64, 32, 16, 16]     149,440\n",
       "|    |    + _DenseLayer (denselayer21): 3-47       [64, 32, 16, 16]     153,600\n",
       "|    |    + _DenseLayer (denselayer22): 3-48       [64, 32, 16, 16]     157,760\n",
       "|    |    + _DenseLayer (denselayer23): 3-49       [64, 32, 16, 16]     161,920\n",
       "|    |    + _DenseLayer (denselayer24): 3-50       [64, 32, 16, 16]     166,080\n",
       "|    + _Transition (transition3): 2-10             [64, 512, 8, 8]      --\n",
       "|    |    + BatchNorm2d (norm): 3-51               [64, 1024, 16, 16]   2,048\n",
       "|    |    + ReLU (relu): 3-52                      [64, 1024, 16, 16]   --\n",
       "|    |    + Conv2d (conv): 3-53                    [64, 512, 16, 16]    524,288\n",
       "|    |    + AvgPool2d (pool): 3-54                 [64, 512, 8, 8]      --\n",
       "|    + _DenseBlock (denseblock4): 2-11             [64, 1024, 8, 8]     --\n",
       "|    |    + _DenseLayer (denselayer1): 3-55        [64, 32, 8, 8]       103,680\n",
       "|    |    + _DenseLayer (denselayer2): 3-56        [64, 32, 8, 8]       107,840\n",
       "|    |    + _DenseLayer (denselayer3): 3-57        [64, 32, 8, 8]       112,000\n",
       "|    |    + _DenseLayer (denselayer4): 3-58        [64, 32, 8, 8]       116,160\n",
       "|    |    + _DenseLayer (denselayer5): 3-59        [64, 32, 8, 8]       120,320\n",
       "|    |    + _DenseLayer (denselayer6): 3-60        [64, 32, 8, 8]       124,480\n",
       "|    |    + _DenseLayer (denselayer7): 3-61        [64, 32, 8, 8]       128,640\n",
       "|    |    + _DenseLayer (denselayer8): 3-62        [64, 32, 8, 8]       132,800\n",
       "|    |    + _DenseLayer (denselayer9): 3-63        [64, 32, 8, 8]       136,960\n",
       "|    |    + _DenseLayer (denselayer10): 3-64       [64, 32, 8, 8]       141,120\n",
       "|    |    + _DenseLayer (denselayer11): 3-65       [64, 32, 8, 8]       145,280\n",
       "|    |    + _DenseLayer (denselayer12): 3-66       [64, 32, 8, 8]       149,440\n",
       "|    |    + _DenseLayer (denselayer13): 3-67       [64, 32, 8, 8]       153,600\n",
       "|    |    + _DenseLayer (denselayer14): 3-68       [64, 32, 8, 8]       157,760\n",
       "|    |    + _DenseLayer (denselayer15): 3-69       [64, 32, 8, 8]       161,920\n",
       "|    |    + _DenseLayer (denselayer16): 3-70       [64, 32, 8, 8]       166,080\n",
       "|    + BatchNorm2d (norm5): 2-12                   [64, 1024, 8, 8]     2,048\n",
       "+ Linear (classifier): 1-2                         [64, 1000]           1,025,000\n",
       "==========================================================================================\n",
       "Total params: 7,978,856\n",
       "Trainable params: 7,978,856\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 236.90\n",
       "==========================================================================================\n",
       "Input size (MB): 50.33\n",
       "Forward/backward pass size (MB): 15091.62\n",
       "Params size (MB): 31.92\n",
       "Estimated Total Size (MB): 15173.86\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torchvision.models.DenseNet121_Weights.DEFAULT\n",
    "model = torchvision.models.densenet121(weights=weights).to(device)\n",
    "torchinfo.summary(\n",
    "    model=model,\n",
    "    input_size=(64,3,256,256),\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\", \"ascii_only\", \"depth\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 20000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy\n",
    "\n",
    "\n",
    "auto_transform = weights.transforms()\n",
    "data = ImageFolderCustom(\n",
    "    targ_dir = data_path,\n",
    "    transform=auto_transform\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "total_samples=len(data)\n",
    "num_samples=100000\n",
    "\n",
    "\n",
    "indices=torch.tensor(numpy.random.permutation(numpy.arange(total_samples))[:num_samples])\n",
    "\n",
    "train_indices=indices[:int(0.8*num_samples)]\n",
    "test_indices=indices[int(0.8*num_samples):]\n",
    "\n",
    "train_dataset=Subset(data, train_indices)\n",
    "test_dataset=Subset(data, test_indices)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type (var_name))                       Output Shape              Param #\n",
       "===============================================================================================\n",
       "DenseNet (DenseNet)                           [64, 2]                   --\n",
       "Sequential (features)                       [64, 1024, 8, 8]          --\n",
       "    Conv2d (conv0)                         [64, 64, 128, 128]        9,408\n",
       "    BatchNorm2d (norm0)                    [64, 64, 128, 128]        128\n",
       "    ReLU (relu0)                           [64, 64, 128, 128]        --\n",
       "    MaxPool2d (pool0)                      [64, 64, 64, 64]          --\n",
       "    _DenseBlock (denseblock1)              [64, 256, 64, 64]         --\n",
       "        _DenseLayer (denselayer1)         [64, 32, 64, 64]          45,440\n",
       "        _DenseLayer (denselayer2)         [64, 32, 64, 64]          49,600\n",
       "        _DenseLayer (denselayer3)         [64, 32, 64, 64]          53,760\n",
       "        _DenseLayer (denselayer4)         [64, 32, 64, 64]          57,920\n",
       "        _DenseLayer (denselayer5)         [64, 32, 64, 64]          62,080\n",
       "        _DenseLayer (denselayer6)         [64, 32, 64, 64]          66,240\n",
       "    _Transition (transition1)              [64, 128, 32, 32]         --\n",
       "        BatchNorm2d (norm)                [64, 256, 64, 64]         512\n",
       "        ReLU (relu)                       [64, 256, 64, 64]         --\n",
       "        Conv2d (conv)                     [64, 128, 64, 64]         32,768\n",
       "        AvgPool2d (pool)                  [64, 128, 32, 32]         --\n",
       "    _DenseBlock (denseblock2)              [64, 512, 32, 32]         --\n",
       "        _DenseLayer (denselayer1)         [64, 32, 32, 32]          53,760\n",
       "        _DenseLayer (denselayer2)         [64, 32, 32, 32]          57,920\n",
       "        _DenseLayer (denselayer3)         [64, 32, 32, 32]          62,080\n",
       "        _DenseLayer (denselayer4)         [64, 32, 32, 32]          66,240\n",
       "        _DenseLayer (denselayer5)         [64, 32, 32, 32]          70,400\n",
       "        _DenseLayer (denselayer6)         [64, 32, 32, 32]          74,560\n",
       "        _DenseLayer (denselayer7)         [64, 32, 32, 32]          78,720\n",
       "        _DenseLayer (denselayer8)         [64, 32, 32, 32]          82,880\n",
       "        _DenseLayer (denselayer9)         [64, 32, 32, 32]          87,040\n",
       "        _DenseLayer (denselayer10)        [64, 32, 32, 32]          91,200\n",
       "        _DenseLayer (denselayer11)        [64, 32, 32, 32]          95,360\n",
       "        _DenseLayer (denselayer12)        [64, 32, 32, 32]          99,520\n",
       "    _Transition (transition2)              [64, 256, 16, 16]         --\n",
       "        BatchNorm2d (norm)                [64, 512, 32, 32]         1,024\n",
       "        ReLU (relu)                       [64, 512, 32, 32]         --\n",
       "        Conv2d (conv)                     [64, 256, 32, 32]         131,072\n",
       "        AvgPool2d (pool)                  [64, 256, 16, 16]         --\n",
       "    _DenseBlock (denseblock3)              [64, 1024, 16, 16]        --\n",
       "        _DenseLayer (denselayer1)         [64, 32, 16, 16]          70,400\n",
       "        _DenseLayer (denselayer2)         [64, 32, 16, 16]          74,560\n",
       "        _DenseLayer (denselayer3)         [64, 32, 16, 16]          78,720\n",
       "        _DenseLayer (denselayer4)         [64, 32, 16, 16]          82,880\n",
       "        _DenseLayer (denselayer5)         [64, 32, 16, 16]          87,040\n",
       "        _DenseLayer (denselayer6)         [64, 32, 16, 16]          91,200\n",
       "        _DenseLayer (denselayer7)         [64, 32, 16, 16]          95,360\n",
       "        _DenseLayer (denselayer8)         [64, 32, 16, 16]          99,520\n",
       "        _DenseLayer (denselayer9)         [64, 32, 16, 16]          103,680\n",
       "        _DenseLayer (denselayer10)        [64, 32, 16, 16]          107,840\n",
       "        _DenseLayer (denselayer11)        [64, 32, 16, 16]          112,000\n",
       "        _DenseLayer (denselayer12)        [64, 32, 16, 16]          116,160\n",
       "        _DenseLayer (denselayer13)        [64, 32, 16, 16]          120,320\n",
       "        _DenseLayer (denselayer14)        [64, 32, 16, 16]          124,480\n",
       "        _DenseLayer (denselayer15)        [64, 32, 16, 16]          128,640\n",
       "        _DenseLayer (denselayer16)        [64, 32, 16, 16]          132,800\n",
       "        _DenseLayer (denselayer17)        [64, 32, 16, 16]          136,960\n",
       "        _DenseLayer (denselayer18)        [64, 32, 16, 16]          141,120\n",
       "        _DenseLayer (denselayer19)        [64, 32, 16, 16]          145,280\n",
       "        _DenseLayer (denselayer20)        [64, 32, 16, 16]          149,440\n",
       "        _DenseLayer (denselayer21)        [64, 32, 16, 16]          153,600\n",
       "        _DenseLayer (denselayer22)        [64, 32, 16, 16]          157,760\n",
       "        _DenseLayer (denselayer23)        [64, 32, 16, 16]          161,920\n",
       "        _DenseLayer (denselayer24)        [64, 32, 16, 16]          166,080\n",
       "    _Transition (transition3)              [64, 512, 8, 8]           --\n",
       "        BatchNorm2d (norm)                [64, 1024, 16, 16]        2,048\n",
       "        ReLU (relu)                       [64, 1024, 16, 16]        --\n",
       "        Conv2d (conv)                     [64, 512, 16, 16]         524,288\n",
       "        AvgPool2d (pool)                  [64, 512, 8, 8]           --\n",
       "    _DenseBlock (denseblock4)              [64, 1024, 8, 8]          --\n",
       "        _DenseLayer (denselayer1)         [64, 32, 8, 8]            103,680\n",
       "        _DenseLayer (denselayer2)         [64, 32, 8, 8]            107,840\n",
       "        _DenseLayer (denselayer3)         [64, 32, 8, 8]            112,000\n",
       "        _DenseLayer (denselayer4)         [64, 32, 8, 8]            116,160\n",
       "        _DenseLayer (denselayer5)         [64, 32, 8, 8]            120,320\n",
       "        _DenseLayer (denselayer6)         [64, 32, 8, 8]            124,480\n",
       "        _DenseLayer (denselayer7)         [64, 32, 8, 8]            128,640\n",
       "        _DenseLayer (denselayer8)         [64, 32, 8, 8]            132,800\n",
       "        _DenseLayer (denselayer9)         [64, 32, 8, 8]            136,960\n",
       "        _DenseLayer (denselayer10)        [64, 32, 8, 8]            141,120\n",
       "        _DenseLayer (denselayer11)        [64, 32, 8, 8]            145,280\n",
       "        _DenseLayer (denselayer12)        [64, 32, 8, 8]            149,440\n",
       "        _DenseLayer (denselayer13)        [64, 32, 8, 8]            153,600\n",
       "        _DenseLayer (denselayer14)        [64, 32, 8, 8]            157,760\n",
       "        _DenseLayer (denselayer15)        [64, 32, 8, 8]            161,920\n",
       "        _DenseLayer (denselayer16)        [64, 32, 8, 8]            166,080\n",
       "    BatchNorm2d (norm5)                    [64, 1024, 8, 8]          2,048\n",
       "Sequential (classifier)                     [64, 2]                   --\n",
       "    Linear (0)                             [64, 2]                   2,050\n",
       "===============================================================================================\n",
       "Total params: 6,955,906\n",
       "Trainable params: 6,955,906\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 236.83\n",
       "===============================================================================================\n",
       "Input size (MB): 50.33\n",
       "Forward/backward pass size (MB): 15091.11\n",
       "Params size (MB): 27.82\n",
       "Estimated Total Size (MB): 15169.26\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape = len(data.classes)\n",
    "\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=1024, out_features=output_shape)\n",
    ").to(device)\n",
    "\n",
    "torchinfo.summary(\n",
    "    model=model,\n",
    "    input_size=(64,3,256,256),\n",
    "    # col_width=20,\n",
    "    row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 1/5 [15:40<1:02:40, 940.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.2035 | train_acc: 0.9227 | test_loss: 0.1747 | test_acc: 0.9326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 2/5 [30:50<46:08, 922.79s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.1832 | train_acc: 0.9296 | test_loss: 0.1528 | test_acc: 0.9422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 3/5 [46:09<30:41, 920.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.1731 | train_acc: 0.9342 | test_loss: 0.3193 | test_acc: 0.8593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 4/5 [1:01:20<15:17, 917.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.1621 | train_acc: 0.9378 | test_loss: 0.1771 | test_acc: 0.9294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [1:16:31<00:00, 918.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.1543 | train_acc: 0.9411 | test_loss: 0.1460 | test_acc: 0.9450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=5,\n",
    "    device=device,\n",
    "    writer=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = Path(\"models/DenseNet-121_100k.pt\")\n",
    "torch.save(obj=model.state_dict(), f=SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0accfcabc8924effaa050ec8eeb8e256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/455954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "from typing import Dict, List, Tuple\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "num_workers = 2\n",
    "data_path = Path(\"/local/scratch/camelyon17/camelyon17_v1.0/patches\")\n",
    "batch_size = 32\n",
    "total_samples, num_samples = 0, 0\n",
    "seed = 42\n",
    "num_clients = 5\n",
    "df = pd.read_csv(\"/local/scratch/camelyon17/camelyon17_v1.0/metadata.csv\")\n",
    "num_test_clients = 1\n",
    "\n",
    "\n",
    "def custom_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGBA')\n",
    "\n",
    "\n",
    "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "    \"\"\"Finds the class folder names in a target directory.\n",
    "    \n",
    "    Assumes target directory is in standard image classification format.\n",
    "\n",
    "    Args:\n",
    "        directory (str): target directory to load classnames from.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], Dict[str, int]]: (list_of_class_names, dict(class_name: idx...))\n",
    "    \n",
    "    Example:\n",
    "        find_classes(\"food_images/train\")\n",
    "        >>> ([\"class_1\", \"class_2\"], {\"class_1\": 0, ...})\n",
    "    \"\"\"\n",
    "    # 1. Get the class names by scanning the target directory\n",
    "    classes = [\"Non-cancerous\", \"Cancerous\"]\n",
    "    \n",
    "    # 2. Raise an error if class names not found\n",
    "    if not classes:\n",
    "        raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
    "        \n",
    "    # 3. Create a dictionary of index labels (computers prefer numerical rather than string labels)\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "    return classes, class_to_idx\n",
    "\n",
    "# Write a custom dataset class (inherits from torch.utils.data.Dataset)\n",
    "\n",
    "# 1. Subclass torch.utils.data.Dataset\n",
    "class ImageFolderCustom(Dataset):\n",
    "    \n",
    "    # 2. Initialize with a targ_dir and transform (optional) parameter\n",
    "    def __init__(self, targ_dir: str, transform=None) -> None:\n",
    "        \n",
    "        # 3. Create class attributes\n",
    "        # Get all image paths\n",
    "        self.paths = list(pathlib.Path(targ_dir).glob(\"*/*.png\")) # note: you'd have to update this if you've got .png's or .jpeg's\n",
    "        # Setup transforms\n",
    "        df = pd.read_csv(\"/local/scratch/camelyon17/camelyon17_v1.0/metadata.csv\")\n",
    "        # for idx in range(len(self.paths)):\n",
    "        #     image_path = self.paths[idx]\n",
    "        #     regex = re.compile(r'patch_patient_(\\d+)_node_(\\d+)_x_(\\d+)_y_(\\d+).png')\n",
    "        #     mo=regex.search(str(image_path)[69:])\n",
    "        #     patient,node,x,y = mo.groups()\n",
    "        #     patient,node,x,y = int(patient), int(node), int(x), int(y)\n",
    "        #     self.center[idx] = int(df[(df[\"patient\"] == patient) & (df[\"node\"] == node) & (df[\"x_coord\"] == x) & (df[\"y_coord\"] == y)][\"center\"].iloc[0])\n",
    "\n",
    "\n",
    "        self.transform = transform\n",
    "        # Create classes and class_to_idx attributes\n",
    "        self.classes, self.class_to_idx = find_classes(targ_dir)\n",
    "\n",
    "    # 4. Make function to load images\n",
    "    def load_image(self, index: int) -> Image.Image:\n",
    "        \"Opens an image via a path and returns it.\"\n",
    "        image_path = self.paths[index]\n",
    "        return Image.open(image_path) \n",
    "    \n",
    "    # 5. Overwrite the __len__() method (optional but recommended for subclasses of torch.utils.data.Dataset)\n",
    "    def __len__(self) -> int:\n",
    "        \"Returns the total number of samples.\"\n",
    "        return len(self.paths)\n",
    "    \n",
    "    # 6. Overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"Returns one sample of data, data and label (X, y).\"\n",
    "        img = self.load_image(index)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img_arr = np.asarray(img)\n",
    "        img = Image.fromarray(img_arr)\n",
    "        image_path = self.paths[index]\n",
    "        regex = re.compile(r'patch_patient_(\\d+)_node_(\\d+)_x_(\\d+)_y_(\\d+).png')\n",
    "        mo=regex.search(str(image_path)[69:])\n",
    "        # print(mo.groups())\n",
    "        patient,node,x,y = mo.groups()\n",
    "        patient,node,x,y = int(patient), int(node), int(x), int(y)\n",
    "\n",
    "        has_cancer = int(df[(df[\"patient\"] == patient) & (df[\"node\"] == node) & (df[\"x_coord\"] == x) & (df[\"y_coord\"] == y)][\"tumor\"].iloc[0])     \n",
    "        class_name  = \"Cancerous\" if has_cancer else \"Non-cancerous\" # expects path in data_folder/class_name/image.jpeg\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "        # Transform if necessary\n",
    "        if self.transform:\n",
    "            return self.transform(img), class_idx # return data, label (X, y)\n",
    "        else:\n",
    "            return img, class_idx # return data, label (X, y)\n",
    "\n",
    "\n",
    "def create_dataloaders(data_transform: transforms.Compose):\n",
    "    random.seed(seed)\n",
    "\n",
    "    paths = list(pathlib.Path(data_path).glob(\"*/*.png\")) # note: you'd have to update this if you've got .png's or .jpeg's\n",
    "    # print(len(paths))\n",
    "    center = []\n",
    "    # # Setup transforms\n",
    "    df = pd.read_csv(\"/local/scratch/camelyon17/camelyon17_v1.0/metadata.csv\")\n",
    "    regex = re.compile(r'patch_patient_(\\d+)_node_(\\d+)_x_(\\d+)_y_(\\d+).png')\n",
    "    for idx in tqdm(range(len(paths))):\n",
    "        image_path = paths[idx]\n",
    "        mo=regex.search(str(image_path)[69:])\n",
    "        patient,node,x,y = mo.groups()\n",
    "        patient,node,x,y = int(patient), int(node), int(x), int(y)\n",
    "        center.append(int(df[(df[\"patient\"] == patient) & (df[\"node\"] == node) & (df[\"x_coord\"] == x) & (df[\"y_coord\"] == y)][\"center\"].iloc[0]))\n",
    "\n",
    "    indices_subsets = {0:[],1:[],2:[],3:[],4:[],}\n",
    "\n",
    "    for i in range(len(center)):\n",
    "        indices_subsets[center[i]].append(i)\n",
    "    \n",
    "    for (key, value) in indices_subsets.items():\n",
    "        random.shuffle(indices_subsets[key])\n",
    "    \n",
    "\n",
    "    data = ImageFolderCustom(\n",
    "        targ_dir = data_path,\n",
    "        transform = data_transform\n",
    "    )\n",
    "\n",
    "    total_samples = len(data)\n",
    "    num_samples = total_samples\n",
    "\n",
    "\n",
    "    train_indices=[]\n",
    "    validate_indices=[]\n",
    "    test_indices=[]\n",
    "\n",
    "    train_client_indices = [0,1,3,4]\n",
    "\n",
    "    for i in range(num_clients):\n",
    "        if(i in train_client_indices):\n",
    "            train_split = int(0.8*len(indices_subsets[i]))\n",
    "            train_indices.append(indices_subsets[i][0:train_split])\n",
    "            validate_indices.append(indices_subsets[i][train_split:])\n",
    "        else:\n",
    "            test_indices.append(indices_subsets[i])\n",
    "\n",
    "    train_datasets = []\n",
    "    validate_datasets = []\n",
    "    test_datasets = []\n",
    "\n",
    "    tr_idx, te_idx = 0,0\n",
    "    for i in range(num_clients):\n",
    "        if(i in train_client_indices):\n",
    "            train_datasets.append(Subset(data, train_indices[tr_idx]))\n",
    "            validate_datasets.append(Subset(data, validate_indices[tr_idx]))\n",
    "            tr_idx+=1\n",
    "        else:\n",
    "            test_datasets.append(Subset(data, test_indices[te_idx]))\n",
    "            te_idx+=1\n",
    "    \n",
    "    train_dataloaders = []\n",
    "    validate_dataloaders = []\n",
    "    test_dataloaders = []\n",
    "\n",
    "    tr_idx, te_idx = 0,0\n",
    "\n",
    "\n",
    "    for i in range(num_clients):\n",
    "        if(i in train_client_indices):\n",
    "            train_dataloaders.append(\n",
    "                DataLoader(\n",
    "                    dataset = train_datasets[tr_idx],\n",
    "                    batch_size = batch_size,\n",
    "                    shuffle = True,\n",
    "                    num_workers = num_workers,\n",
    "                    pin_memory = True\n",
    "            ))\n",
    "\n",
    "            validate_dataloaders.append(\n",
    "                DataLoader(\n",
    "                    dataset = validate_datasets[tr_idx],\n",
    "                    batch_size = batch_size,\n",
    "                    shuffle = True,\n",
    "                    num_workers = num_workers,\n",
    "                    pin_memory = True\n",
    "                )\n",
    "            )\n",
    "\n",
    "            tr_idx += 1\n",
    "\n",
    "        else:\n",
    "            test_dataloaders.append(\n",
    "                DataLoader(\n",
    "                    dataset = test_datasets[te_idx],\n",
    "                    batch_size = batch_size,\n",
    "                    shuffle = True,\n",
    "                    num_workers = num_workers,\n",
    "                    pin_memory = True\n",
    "                )\n",
    "            )\n",
    "            te_idx += 1\n",
    "\n",
    "    return train_dataloaders, validate_dataloaders, test_dataloaders\n",
    "    \n",
    "a,b,c = create_dataloaders(None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
